%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Adithya Sagar at 2016-02-22 18:18:37 -0500 


%% Saved with string encoding Unicode (UTF-8) 


@preamble{"\newcommand{\noopsort}[1]{} "}



@article{regis-2007,
	Author = {Rommel G. Regis;Christine A. Shoemaker},
	Date-Added = {2016-02-22 23:14:20 +0000},
	Date-Modified = {2016-02-22 23:18:36 +0000},
	Journal = {INFORMS Journal on Computing},
	Title = {A Stochastic Radial Basis Function Method For Global Optimization of Expensive Functions},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QOi4uLy4uLy4uLy4uL1NlbSA0L0NFRSA2MDA1L1JlZ2lzIGFuZCBTaG9lIElORk9STVMgMjAwNy5wZGbSFwsYGVdOUy5kYXRhTxEB9AAAAAAB9AACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA0GYyF0grAAAADZhvH1JlZ2lzIGFuZCBTaG9lIElORk9STVMgMjAwNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANmcvPM1diAAAAAAAAAAAABAADAAAJIAAAAAAAAAAAAAAAAAAAAAhDRUUgNjAwNQAQAAgAANBmalcAAAARAAgAAM8znbIAAAABABgADZhvAA2YbQANig4ADYn1AAk+uAACk9UAAgBbTWFjaW50b3NoIEhEOlVzZXJzOgBBZGk6AENvcm5lbGw6AENvdXJzZXM6AFNlbSA0OgBDRUUgNjAwNToAUmVnaXMgYW5kIFNob2UgSU5GT1JNUyAyMDA3LnBkZgAADgBAAB8AUgBlAGcAaQBzACAAYQBuAGQAIABTAGgAbwBlACAASQBOAEYATwBSAE0AUwAgADIAMAAwADcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAEhVc2Vycy9BZGkvQ29ybmVsbC9Db3Vyc2VzL1NlbSA0L0NFRSA2MDA1L1JlZ2lzIGFuZCBTaG9lIElORk9STVMgMjAwNy5wZGYAEwABLwAAFQACAAr//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgDLANAA2ALQAtIC1wLiAusC+QL9AwQDDQMSAx8DIgM0AzcDPAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAM+}}

@article{MOV2012,
	Author = {Mahoney, Michael W. and Orecchia, Lorenzo and Vishnoi, Nisheeth K.},
	Journal = {Journal of Machine Learning Research},
	Pages = {2339--2365},
	Title = {A local spectral method for graphs: with applications to improving graph partitions and exploring data graphs locally},
	Volume = {13},
	Year = {2012}}

@inproceedings{GS12,
	Author = {David F. Gleich and C. Seshadhri},
	Booktitle = {KDD '2012},
	Title = {Vertex neighborhoods, low conductance cuts, and good seeds for local community methods},
	Year = {2012}}

@article{SM00,
	Author = {J. Shi and J. Malik},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {8},
	Pages = {888-905},
	Title = {Normalized cuts and image segmentation},
	Volume = {22},
	Year = {2000}}

@article{S07,
	Author = {S. E. Schaeffer},
	Journal = {Computer Science Review,},
	Number = {1},
	Pages = {27-64},
	Title = {Graph clustering},
	Volume = {1},
	Year = {2007}}

@inproceedings{silvio-security13,
	Author = {L. Alvisi and A. Clement and A. Epasto and S. Lattanzi and A. Panconesi},
	Booktitle = {IEEE Symposium on Security and Privacy},
	Title = {The evolution of sybil defense via social networks},
	Year = {2013}}

@article{LLDM09,
	Author = {Jure Leskovec and Kevin J. Lang and Anirban Dasgupta and Michael W. Mahoney},
	Journal = {Internet Mathematics},
	Number = {1},
	Pages = {29-123},
	Title = {Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters},
	Volume = {6},
	Year = {2009}}

@inproceedings{GLMY11,
	Author = {Ullas Gargi and Wenjun Lu and Vahab S. Mirrokni and Sangho Yoon},
	Booktitle = {AAAI Conference on Weblogs and Social Media},
	Title = {Large-Scale Community Detection on YouTube for Topic Discovery and Exploration},
	Year = {2011}}

@inproceedings{AGM12,
	Author = {Andersen, Reid and Gleich, David F. and Mirrokni, Vahab},
	Pages = {273--282},
	Series = {WSDM '12},
	Title = {Overlapping clusters for distributed computation},
	Year = {2012}}

@inproceedings{AndersenPeres09,
	Author = {Reid Andersen and Yuval Peres},
	Series = {STOC},
	Title = {Finding sparse cuts locally using evolving sets},
	Year = {2009}}

@inproceedings{MorrisPeres03,
	Author = {Morris, Ben and Peres, Yuval},
	Location = {San Diego, CA, USA},
	Numpages = {8},
	Pages = {279--286},
	Publisher = {ACM},
	Series = {STOC '03},
	Title = {Evolving sets and mixing},
	Year = {2003}}

@article{ST08c,
	Abstract = {We present a randomized algorithm that, on input a symmetric, weakly diagonally dominant n-by-n matrix A with m nonzero entries and an n-vector b, produces a y such that \$\backslash norm\{y - \backslash pinv\{A\} b\}\_\{A\} \backslash leq \backslash epsilon \backslash norm\{\backslash pinv\{A\} b\}\_\{A\}\$ in expected time \$O (m \backslash log\^{}\{c\}n \backslash log (1/\backslash epsilon)),\$ for some constant c. By applying this algorithm inside the inverse power method, we compute approximate Fiedler vectors in a similar amount of time. The algorithm applies subgraph preconditioners in a recursive fashion. These preconditioners improve upon the subgraph preconditioners first introduced by Vaidya (1990). For any symmetric, weakly diagonally-dominant matrix A with non-positive off-diagonal entries and \$k \backslash geq 1\$, we construct in time \$O (m \backslash log\^{}\{c\} n)\$ a preconditioner B of A with at most \$2 (n - 1) + O ((m/k) \backslash log\^{}\{39\} n)\$ nonzero off-diagonal entries such that the finite generalized condition number \$\backslash kappa\_\{f\} (A,B)\$ is at most k, for some other constant c. In the special case when the nonzero structure of the matrix is planar the corresponding linear system solver runs in expected time \$ O (n \backslash log\^{}\{2\} n + n \backslash log n \backslash \backslash log \backslash log n \backslash \backslash log (1/\backslash epsilon))\$. We hope that our introduction of algorithms of low asymptotic complexity will lead to the development of algorithms that are also fast in practice.},
	Archiveprefix = {arXiv},
	Arxivid = {cs/0607105},
	Author = {Spielman, Daniel A. and Teng, Shang-Hua},
	Doi = {10.1137/090771430},
	Eprint = {0607105},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2006 - Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric, Diagonally Dominant Linear Systems.pdf:pdf},
	Issn = {0895-4798},
	Journal = {SIAM Journal on Matrix Analysis and Applications},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = jul,
	Number = {3},
	Pages = {835--885},
	Primaryclass = {cs},
	Title = {{Nearly Linear Time Algorithms for Preconditioning and Solving Symmetric, Diagonally Dominant Linear Systems}},
	Volume = {35},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/090771430}}

@article{ST08a,
	Abstract = {We study the design of local algorithms for massive graphs. A local algorithm is one that finds a solution containing or near a given vertex without looking at the whole graph. We present a local clustering algorithm. Our algorithm finds a good cluster--a subset of vertices whose internal connections are significantly richer than its external connections--near a given vertex. The running time of our algorithm, when it finds a non-empty local cluster, is nearly linear in the size of the cluster it outputs. Our clustering algorithm could be a useful primitive for handling massive graphs, such as social networks and web-graphs. As an application of this clustering algorithm, we present a partitioning algorithm that finds an approximate sparsest cut with nearly optimal balance. Our algorithm takes time nearly linear in the number edges of the graph. Using the partitioning algorithm of this paper, we have designed a nearly-linear time algorithm for constructing spectral sparsifiers of graphs, which we in turn use in a nearly-linear time algorithm for solving linear systems in symmetric, diagonally-dominant matrices. The linear system solver also leads to a nearly linear-time algorithm for approximating the second-smallest eigenvalue and corresponding eigenvector of the Laplacian matrix of a graph. These other results are presented in two companion papers.},
	Archiveprefix = {arXiv},
	Arxivid = {0809.3232},
	Author = {Spielman, Daniel A. and Teng, Shang-Hua},
	Doi = {10.1137/080744888},
	Eprint = {0809.3232},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2013 - A Local Clustering Algorithm for Massive Graphs and Its Application to Nearly Linear Time Graph Partitioning.pdf:pdf},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Mendeley-Groups = {Algorithms/Sparsest Cut/Local Clustering,Algorithms/Sparsification},
	Month = jan,
	Number = {1},
	Pages = {1--26},
	Title = {{A Local Clustering Algorithm for Massive Graphs and Its Application to Nearly Linear Time Graph Partitioning}},
	Volume = {42},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/080744888}}

@article{ST08b,
	Abstract = {We introduce a new notion of graph sparsificaiton based on spectral similarity of graph Laplacians: spectral sparsification requires that the Laplacian quadratic form of the sparsifier approximate that of the original. This is equivalent to saying that the Laplacian of the sparsifier is a good preconditioner for the Laplacian of the original. We prove that every graph has a spectral sparsifier of nearly linear size. Moreover, we present an algorithm that produces spectral sparsifiers in time \$\backslash softO\{m\}\$, where \$m\$ is the number of edges in the original graph. This construction is a key component of a nearly-linear time algorithm for solving linear equations in diagonally-dominant matrcies. Our sparsification algorithm makes use of a nearly-linear time algorithm for graph partitioning that satisfies a strong guarantee: if the partition it outputs is very unbalanced, then the larger part is contained in a subgraph of high conductance.},
	Archiveprefix = {arXiv},
	Arxivid = {0808.4134},
	Author = {Spielman, Daniel A. and Teng, Shang-Hua},
	Doi = {10.1137/08074489X},
	Eprint = {0808.4134},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2008 - Spectral Sparsification of Graphs.pdf:pdf},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = jan,
	Number = {4},
	Pages = {981--1025},
	Title = {{Spectral Sparsification of Graphs}},
	Volume = {40},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/08074489X}}

@article{ACL06,
	Author = {Reid Andersen and Fan Chung and Kevin Lang},
	Ee = {http://www.math.ucsd.edu/~fan/wp/localpartfull.pdf},
	Note = {An extended abstract appeared in FOCS '2006},
	Title = {Using PageRank to Locally Partition a Graph},
	Year = {2006}}

@article{CKKRS06,
	Author = {Chawla, Shuchi and Krauthgamer, Robert and Kumar, Ravi and Rabani, Yuval and Sivakumar, D.},
	Journal = {Computational Complexity},
	Month = jun,
	Number = {2},
	Numpages = {21},
	Pages = {94--114},
	Publisher = {Birkhauser Verlag},
	Title = {On the Hardness of Approximating Multicut and Sparsest-Cut},
	Volume = {15},
	Year = {2006}}

@article{Alon86,
	Author = {Noga Alon},
	Journal = {Combinatorica},
	Number = {2},
	Pages = {83-96},
	Title = {Eigenvalues and expanders},
	Volume = {6},
	Year = {1986}}

@inproceedings{ZCZ09,
	Author = {Zhu, Zeyuan Allen and Chen, Weizhu and Zhu, Chenguang and Wang, Gang and Wang, Haixun and Chen, Zheng},
	Series = {ICDM},
	Title = {Inverse Time Dependency in Convex Regularized Learning},
	Year = {2009}}

@inproceedings{SS08,
	Author = {Shai {Shalev-Shwartz} and Nathan Srebro},
	Booktitle = {ICML},
	Title = {{SVM} optimization: inverse dependence on training set size},
	Year = {2008}}

@article{SinclairJerrum89,
	Author = {Alistair Sinclair and Mark Jerrum},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Ee = {http://dx.doi.org/10.1016/0890-5401(89)90067-9},
	Journal = {Information and Computation},
	Number = {1},
	Pages = {93-133},
	Title = {Approximate Counting, Uniform Generation and Rapidly Mixing Markov Chains},
	Volume = {82},
	Year = {1989}}

@article{LeightonRao99,
	Author = {Frank Thomson Leighton and Satish Rao},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Ee = {http://doi.acm.org/10.1145/331524.331526},
	Journal = {Journal of the ACM},
	Number = {6},
	Pages = {787-832},
	Title = {Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms},
	Volume = {46},
	Year = {1999}}

@article{ARV09,
	Author = {Sanjeev Arora and Satish Rao and Umesh V. Vazirani},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Ee = {http://doi.acm.org/10.1145/1502793.1502794},
	Journal = {Journal of the ACM},
	Number = {2},
	Title = {Expander flows, geometric embeddings and graph partitioning},
	Volume = {56},
	Year = {2009}}

@inproceedings{Sherman09,
	Author = {Sherman, Jonah},
	Booktitle = {Proceedings of the 50th Annual IEEE Symposium on Foundations of Computer Science},
	Numpages = {10},
	Pages = {363--372},
	Series = {FOCS '09},
	Title = {Breaking the Multicommodity Flow Barrier for $O(\sqrt{\log n})$-Approximations to Sparsest Cut},
	Year = {2009}}

@inproceedings{ST04,
	Address = {New York, New York, USA},
	Author = {Spielman, Daniel A. and Teng, Shang-Hua},
	Booktitle = {Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04},
	Doi = {10.1145/1007352.1007372},
	Isbn = {1581138520},
	Mendeley-Groups = {Algorithms/Sparsification},
	Pages = {81},
	Publisher = {ACM Press},
	Title = {{Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems}},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1007352.1007372}}

@inproceedings{GharanTrevisan12,
	Author = {Gharan, Shayan Oveis and Trevisan, Luca},
	Pages = {187-196},
	Series = {FOCS},
	Title = {Approximating the Expansion Profile and Almost Optimal Local Graph Clustering},
	Year = {2012}}

@article{KVV04,
	Author = {Ravi Kannan and Santosh Vempala and Adrian Vetta},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Ee = {http://doi.acm.org/10.1145/990308.990313},
	Journal = {Journal of the ACM},
	Number = {3},
	Pages = {497-515},
	Title = {On clusterings: Good, bad and spectral},
	Volume = {51},
	Year = {2004}}

@inproceedings{MMV12,
	Author = {Konstantin Makarychev and Yury Makarychev and Aravindan Vijayaraghavan},
	Booktitle = {STOC '12},
	Ee = {http://doi.acm.org/10.1145/2213977.2214013},
	Pages = {367-384},
	Title = {Approximation algorithms for semi-random partitioning problems},
	Year = {2012}}

@article{PageRank-BrinPage98,
	Author = {Sergey Brin and Lawrence Page},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Ee = {http://dx.doi.org/10.1016/S0169-7552(98)00110-X},
	Journal = {Computer Networks},
	Number = {1-7},
	Pages = {107-117},
	Title = {The Anatomy of a Large-Scale Hypertextual Web Search Engine},
	Volume = {30},
	Year = {1998}}

@inproceedings{Haveliwala02,
	Author = {Taher H. Haveliwala},
	Booktitle = {WWW '02},
	Pages = {517-526},
	Title = {Topic-sensitive PageRank},
	Year = {2002}}

@inproceedings{LovaszSimonovits90,
	Author = {L{\'a}szl{\'o} Lov{\'a}sz and Mikl{\'o}s Simonovits},
	Pages = {346-354},
	Series = {FOCS},
	Title = {The mixing rate of Markov chains, an isoperimetric inequality, and computing the volume},
	Year = {1990}}

@article{LovaszSimonovits93,
	Author = {L{\'a}szl{\'o} Lov{\'a}sz and Mikl{\'o}s Simonovits},
	Journal = {Random Struct. Algorithms},
	Number = {4},
	Pages = {359-412},
	Title = {Random Walks in a Convex Body and an Improved Volume Algorithm},
	Volume = {4},
	Year = {1993}}

@article{CosinePowerSum,
	Author = {Mircea Merca},
	Journal = {Journal of Integer Sequences},
	Month = {May},
	Pages = {12.5.3},
	Title = {A Note on Cosine Power Sums},
	Volume = {15},
	Year = {2012}}

@book{RandomizedAlgorithms,
	Address = {New York, NY, USA},
	Author = {Motwani, Rajeev and Raghavan, Prabhakar},
	Publisher = {Cambridge University Press},
	Title = {Randomized algorithms},
	Year = {1995}}

@inproceedings{NIPS12-WLSWC,
	Author = {Wu, Xiao-Ming and Li, Zhenguo and So, Anthony Man-Cho and Wright, John and Chang, Shih-Fu},
	Booktitle = {NIPS},
	Title = {Learning with Partially Absorbing Random Walks},
	Year = {2012}}

@inproceedings{LinCohen10,
	Author = {Frank Lin and William W. Cohen},
	Booktitle = {ICML '10},
	Pages = {655-662},
	Title = {Power Iteration Clustering},
	Year = {2010}}

@inproceedings{AndersenLang06WWW,
	Author = {Andersen, Reid and Lang, Kevin J.},
	Pages = {223--232},
	Series = {WWW '06},
	Title = {Communities from seed sets},
	Year = {2006}}

@inproceedings{LLM10WWW,
	Author = {Leskovec, Jure and Lang, Kevin J. and Mahoney, Michael},
	Pages = {631--640},
	Series = {WWW},
	Title = {Empirical comparison of algorithms for network community detection},
	Year = {2010}}

@inproceedings{AndersenLang2008,
	Author = {Andersen, Reid and Lang, Kevin J.},
	Pages = {651--660},
	Series = {SODA},
	Title = {An algorithm for improving graph partitions},
	Year = {2008}}

@inproceedings{ZLM13,
	Author = {Zeyuan Allen Zhu and Silvio Lattanzi and Vahab Mirrokni},
	Booktitle = {ICML},
	Title = {A Local Algorithm for Finding Well-Connected Clusters},
	Year = {2013}}

@inproceedings{Alamgir2010,
	Author = {Alamgir, Morteza and von Luxburg, Ulrike},
	Pages = {18--27},
	Series = {ICDM '10},
	Title = {Multi-agent Random Walks for Local Clustering on Graphs},
	Year = {2010}}

@article{SleatorTarjan1983,
	Author = {Sleator, Daniel D. and Tarjan, Robert Endre},
	Journal = {Journal of computer and system sciences},
	Number = {3},
	Title = {A data structure for dynamic trees},
	Volume = {26},
	Year = {1983}}

@article{Dinic1970,
	Author = {Dinic, E. A.},
	Journal = {Soviet Math Doklady},
	Pages = {1277--1280},
	Title = {Algorithm for solution of a problem of maximum flow in networks with power estimation},
	Volume = {11},
	Year = {1970}}

@article{Gallo1989,
	Author = {Gallo, Giorgio and Grigoriadis, Michael D. and Tarjan, Robert E.},
	Journal = {SIAM Journal on Computing},
	Month = feb,
	Number = {1},
	Pages = {30--55},
	Title = {A Fast Parametric Maximum Flow Algorithm and Applications},
	Volume = {18},
	Year = {1989}}

@article{Goldberg1998,
	Author = {Goldberg, Andrew V. and Rao, Satish},
	Journal = {Journal of the ACM},
	Month = sep,
	Number = {5},
	Pages = {783--797},
	Title = {Beyond the flow decomposition barrier},
	Volume = {45},
	Year = {1998}}

@article{FeigeKrauthgamer02,
	Author = {Feige, Uriel and Krauthgamer, Robert},
	Issue_Date = {2002},
	Journal = {SIAM J. Comput.},
	Month = apr,
	Number = {4},
	Numpages = {29},
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {A Polylogarithmic Approximation of the Minimum Bisection},
	Volume = {31},
	Year = {2002}}

@inproceedings{HHR03,
	Author = {Harrelson, Chris and Hildrum, Kirsten and Rao, Satish},
	Isbn = {1-58113-661-7},
	Numpages = {10},
	Pages = {34--43},
	Series = {SPAA '03},
	Title = {A polynomial-time tree decomposition to minimize congestion},
	Year = {2003}}

@article{LangRao2004,
	Author = {Lang, Kevin and Rao, Satish},
	Journal = {Integer Programming and Combinatorial Optimization},
	Pages = {325--337},
	Title = {{A flow-based method for improving the expansion or conductance of graph cuts}},
	Volume = {3064},
	Year = {2004}}

@article{METIS1998,
	Author = {Karypis, George and Kumar, Vipin},
	Journal = {SIAM Journal on Scientific Computing},
	Month = jan,
	Number = {1},
	Pages = {359--392},
	Title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
	Volume = {20},
	Year = {1998}}

@inproceedings{Kwok2013,
	Author = {Kwok, Tsz Chiu and Lau, Lap Chi and Lee, Yin Tat and Gharan, Shayan Oveis and Trevisan, Luca},
	Booktitle = {STOC 2013},
	Month = jan,
	Title = {Improved Cheeger's Inequality: Analysis of Spectral Partitioning Algorithms through Higher Order Spectral Gap},
	Year = {2013}}

@inproceedings{KRV2006,
	Author = {Khandekar, Rohit and Rao, Satish and Vazirani, Umesh},
	Booktitle = {STOC '06},
	Title = {Graph partitioning using single commodity flows},
	Year = {2006}}

@inproceedings{OSVV2008,
	Address = {New York, New York, USA},
	Author = {Orecchia, Lorenzo and Schulman, Leonard J. and Vazirani, Umesh V. and Vishnoi, Nisheeth K.},
	Booktitle = {STOC 08},
	Title = {On partitioning graphs via single commodity flows},
	Year = {2008}}

@inproceedings{OSV12,
	Author = {Orecchia, Lorenzo and Sachdeva, Sushant and Vishnoi, Nisheeth K.},
	Booktitle = {STOC '12},
	Month = nov,
	Publisher = {ACM Press},
	Title = {Approximating the exponential, the lanczos method and an $\tilde{O}(m)$-time spectral algorithm for balanced separator},
	Year = {2012}}

@inproceedings{CKMST2011,
	Abstract = {We introduce a new approach to computing an approximately maximum s-t flow in a capacitated, undirected graph. This flow is computed by solving a sequence of electrical flow problems. Each electrical flow is given by the solution of a system of linear equations in a Laplacian matrix, and thus may be approximately computed in nearly-linear time. Using this approach, we develop the fastest known algorithm for computing approximately maximum s-t flows. For a graph having n vertices and m edges, our algorithm computes a (1-$\backslash$epsilon)-approximately maximum s-t flow in time $\backslash$tilde\{O\}(mn\^{}\{1/3\} $\backslash$epsilon\^{}\{-11/3\}). A dual version of our approach computes a (1+$\backslash$epsilon)-approximately minimum s-t cut in time $\backslash$tilde\{O\}(m+n\^{}\{4/3\}$\backslash$eps\^{}\{-8/3\}), which is the fastest known algorithm for this problem as well. Previously, the best dependence on m and n was achieved by the algorithm of Goldberg and Rao (J. ACM 1998), which can be used to compute approximately maximum s-t flows in time $\backslash$tilde\{O\}(m$\backslash$sqrt\{n\}$\backslash$epsilon\^{}\{-1\}), and approximately minimum s-t cuts in time $\backslash$tilde\{O\}(m+n\^{}\{3/2\}$\backslash$epsilon\^{}\{-3\}).},
	Address = {New York, New York, USA},
	Archiveprefix = {arXiv},
	Arxivid = {1010.2921},
	Author = {Christiano, Paul and Kelner, Jonathan A. and Madry, Aleksander and Spielman, Daniel A. and Teng, Shang-Hua},
	Booktitle = {Proceedings of the 43rd annual ACM symposium on Theory of computing - STOC '11},
	Doi = {10.1145/1993636.1993674},
	Eprint = {1010.2921},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Christiano et al. - 2011 - Electrical flows, laplacian systems, and faster approximation of maximum flow in undirected graphs.pdf:pdf},
	Isbn = {9781450306911},
	Mendeley-Groups = {Algorithms/Maxflow},
	Month = oct,
	Pages = {273},
	Publisher = {ACM Press},
	Title = {{Electrical flows, laplacian systems, and faster approximation of maximum flow in undirected graphs}},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1993636.1993674}}

@inproceedings{ImprovedCheeger2013,
	Author = {Kwok, Tsz Chiu and Lau, Lap Chi and Lee, Yin Tat and {Oveis Gharan}, Shayan and Trevisan, Luca},
	Booktitle = {STOC '13},
	Month = jan,
	Title = {Improved Cheeger's Inequality: Analysis of Spectral Partitioning Algorithms through Higher Order Spectral Gap},
	Year = {2013}}

@article{Awerbuch2008,
	Address = {New York, New York, USA},
	Author = {Awerbuch, Baruch and Khandekar, Rohit},
	Doi = {10.1145/1374376.1374476},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Awerbuch, Khandekar - 2008 - Stateless distributed gradient descent for positive linear programs.pdf:pdf},
	Isbn = {9781605580470},
	Journal = {Proceedings of the fourtieth annual ACM symposium on Theory of computing - STOC 08},
	Keywords = {convergence,distributed and stateless algorithms,fast,gradient descent,linear programming},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Pages = {691},
	Publisher = {ACM Press},
	Title = {{Stateless distributed gradient descent for positive linear programs}},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1374376.1374476}}

@inproceedings{Young2001,
	Author = {Young, Neal E.},
	Booktitle = {42nd Annual IEEE Symposium on Foundations of Computer Science (FOCS'01)},
	Doi = {10.1109/SFCS.2001.959930},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Young - 2001 - Sequential and parallel algorithms for mixed packing and covering.pdf:pdf},
	Isbn = {0-7695-1116-3},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Pages = {538--546},
	Publisher = {IEEE Comput. Soc},
	Title = {{Sequential and parallel algorithms for mixed packing and covering}},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SFCS.2001.959930}}

@inproceedings{LubyNisan1993,
	Address = {New York, New York, USA},
	Author = {Luby, Michael and Nisan, Noam},
	Booktitle = {Proceedings of the twenty-fifth annual ACM symposium on Theory of computing - STOC '93},
	Doi = {10.1145/167088.167211},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Luby, Nisan - 1993 - A parallel approximation algorithm for positive linear programming.pdf:pdf},
	Isbn = {0897915917},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Pages = {448--457},
	Publisher = {ACM Press},
	Title = {{A parallel approximation algorithm for positive linear programming}},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/167088.167211}}

@article{JainYao2011,
	Author = {Jain, Rahul and Yao, Penghui},
	Doi = {10.1109/FOCS.2011.25},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Jain, Yao - 2011 - A Parallel Approximation Algorithm for Positive Semidefinite Programming.pdf:pdf},
	Isbn = {978-0-7695-4571-4},
	Journal = {2011 IEEE 52nd Annual Symposium on Foundations of Computer Science},
	Keywords = {-fast parallel algorithms,gramming,multiplicative weight update,positive semidefinite pro-},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/SDP},
	Month = oct,
	Pages = {463--471},
	Publisher = {Ieee},
	Title = {{A Parallel Approximation Algorithm for Positive Semidefinite Programming}},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/FOCS.2011.25}}

@inproceedings{BartalByersRaz1997,
	Author = {Bartal, Yair and Byers, John W. and Raz, Danny},
	Booktitle = {Proceedings 38th Annual Symposium on Foundations of Computer Science},
	Doi = {10.1109/SFCS.1997.646119},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Bartal, Byers, Raz - 1997 - Global optimization using local information with applications to flow control.pdf:pdf},
	Isbn = {0-8186-8197-7},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Pages = {303--312},
	Publisher = {IEEE Comput. Soc},
	Title = {{Global optimization using local information with applications to flow control}},
	Year = {1997},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SFCS.1997.646119}}

@article{BartalByersRaz2004,
	Author = {Bartal, Yair and Byers, John W. and Raz, Danny},
	Doi = {10.1137/S0097539700379383},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Bartal, Byers, Raz - 2004 - Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control.pdf:pdf},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Keywords = {1,10,1137,68w15,68w25,ams subject classifications,approximation algorithm,doi,environment must make decisions,flow control,introduction,linear programming,primal-dual,processors in a distributed,s0097539700379383},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Month = jan,
	Number = {6},
	Pages = {1261--1279},
	Title = {{Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control}},
	Volume = {33},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S0097539700379383}}

@article{KoufogiannakisYoung2013,
	Abstract = {We give an approximation algorithm for packing and covering linear programs (linear programs with non-negative coefficients). Given a constraint matrix with n non-zeros, r rows, and c columns, the algorithm computes feasible primal and dual solutions whose costs are within a factor of 1+eps of the optimal cost in time O((r+c)log(n)/eps\^{}2 + n).},
	Author = {Koufogiannakis, Christos and Young, Neal E.},
	Doi = {10.1007/s00453-013-9771-6},
	Issn = {0178-4617},
	Journal = {Algorithmica},
	Month = mar,
	Note = {Previously appeared in FOCS '07.},
	Pages = {494--506},
	Title = {{A Nearly Linear-Time PTAS for Explicit Fractional Packing and Covering Linear Programs}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00453-013-9771-6}}

@inproceedings{PengTangwongsan2012,
	Address = {New York, New York, USA},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1201.5135v1},
	Author = {Peng, Richard and Tangwongsan, Kanat},
	Booktitle = {Proceedinbgs of the 24th ACM symposium on Parallelism in algorithms and architectures - SPAA '12},
	Doi = {10.1145/2312005.2312026},
	Eprint = {arXiv:1201.5135v1},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Peng, Tangwongsan - 2012 - Faster and simpler width-independent parallel algorithms for positive semidefinite programming.pdf:pdf},
	Isbn = {9781450312134},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/SDP},
	Month = jan,
	Pages = {101},
	Publisher = {ACM Press},
	Title = {{Faster and simpler width-independent parallel algorithms for positive semidefinite programming}},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2312005.2312026}}

@techreport{JainYao2012,
	Abstract = {We present a parallel approximation algorithm for a class of mixed packing and covering semidefinite programs which generalize on the class of positive semidefinite programs as considered by Jain and Yao [2011]. As a corollary we get a faster approximation algorithm for positive semidefinite programs with better dependence of the parallel running time on the approximation factor, as compared to that of Jain and Yao [2011]. Our algorithm and analysis is on similar lines as that of Young [2001] who considered analogous linear programs.},
	Archiveprefix = {arXiv},
	Arxivid = {1201.6090},
	Author = {Jain, Rahul and Yao, Penghui},
	Booktitle = {arXiv preprint arXiv:1201.6090},
	Eprint = {1201.6090},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop//Jain, Yao - 2012 - A parallel approximation algorithm for mixed packing and covering semidefinite programs.pdf:pdf},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/SDP},
	Month = jan,
	Pages = {8},
	Title = {{A parallel approximation algorithm for mixed packing and covering semidefinite programs}},
	Year = {2012}}

@inproceedings{Nesterov1983,
	Author = {Nesterov, Yurii},
	Booktitle = {Doklady AN SSSR (translated as Soviet Mathematics Doklady)},
	Pages = {543--547},
	Title = {A method of solving a convex programming problem with convergence rate {$O(1/k^2)$}},
	Volume = {269},
	Year = {1983}}

@book{Nesterov2004,
	Author = {Nesterov, Yurii},
	Isbn = {1402075537},
	Publisher = {Kluwer Academic Publishers},
	Title = {Introductory Lectures on Convex Programming Volume: A Basic course},
	Volume = {I},
	Year = {2004}}

@article{Nesterov2005,
	Abstract = {In this paper we propose a new approach for constructing efficient schemes for non- smooth convex optimization. It is based on a special smoothing technique, which can be applied to the functions with explicit max-structure. Our approach can be considered as an alternative to black-box minimization. From the viewpoint of efficiency estimates, we manage to improve the traditional bounds on the number of iterations of the gra- dient schemes from O 1 unchanged. 2 to O1, keeping basically the complexity of each iteration},
	Author = {Nesterov, Yurii},
	Doi = {10.1007/s10107-004-0552-5},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Nesterov - 2005 - Smooth minimization of non-smooth functions.pdf:pdf},
	Isbn = {1010700405},
	Issn = {0025-5610},
	Journal = {Mathematical Programming},
	Keywords = {complexity theory,convex optimization,non smooth optimization,optimal methods,optimization,structural optimization},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Mendeley-Tags = {optimization},
	Month = dec,
	Number = {1},
	Pages = {127--152},
	Title = {{Smooth minimization of non-smooth functions}},
	Volume = {103},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10107-004-0552-5}}

@article{Nesterov2009,
	Abstract = {In this paper we present a new approach for constructing subgradient schemesfordifferent types ofnonsmoothproblems withconvexstructure.Ourmethods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexi- bility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform bounded- ness of subgradients).We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequali- ties, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds.},
	Annote = {A good citation to his dual averaging.},
	Author = {Nesterov, Yurii},
	Doi = {10.1007/s10107-007-0149-x},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Nesterov - 2007 - Primal-dual subgradient methods for convex problems.pdf:pdf},
	Issn = {0025-5610},
	Journal = {Mathematical Programming},
	Keywords = {Black-box methods,Convex optimization,Lower complexity bounds,Minimax problems,Non-smooth optimization,Saddle points,Stochastic optimization,Subgradient methods,Variational inequalities},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = jun,
	Number = {1},
	Pages = {221--259},
	Title = {{Primal-dual subgradient methods for convex problems}},
	Volume = {120},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10107-007-0149-x}}

@article{AHK2012,
	Author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
	Doi = {10.4086/toc.2012.v008a006},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Hazan, Kale - 2012 - The Multiplicative Weights Update Method a Meta-Algorithm and Applications.pdf:pdf},
	Journal = {Theory of Computing},
	Mendeley-Groups = {Algorithms/Multiplicative Weight},
	Pages = {121--164},
	Title = {{The Multiplicative Weights Update Method: a Meta-Algorithm and Applications.}},
	Volume = {8},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.4086/toc.2012.v008a006}}

@book{Nemirovsky1978,
	Author = {Nemirovsky, Arkadi and Yudin, David},
	Note = {John Wiley, New York (in English) 1983},
	Publisher = {Nauka Publishers, Moscow (in Russian)},
	Title = {Problem complexity and method efficiency in optimization.},
	Year = {1978}}

@book{Nemirovski2013,
	Author = {{Ben-Tal}, Aharon and Nemirovski, Arkadi},
	Doi = {10.1137/1.9780898718829},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Ben-Tal, Nemirovski - 2013 - Lectures on Modern Convex Optimization.pdf:pdf},
	Isbn = {978-0-89871-491-3},
	Mendeley-Groups = {Optimization/Gradient Descent Theory,Books/Optimization},
	Month = jan,
	Publisher = {Society for Industrial and Applied Mathematics},
	Title = {{Lectures on Modern Convex Optimization}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/1.9780898718829}}

@misc{Juditsky13-lecture,
	Author = {Anatoli Juditsky},
	Howpublished = {Lecture notes},
	Month = {November},
	Title = {Convex Optimization II: Algorithms},
	Year = {2013}}

@article{Trevisan1998,
	Author = {Trevisan, Luca},
	Doi = {10.1007/PL00009209},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Trevisan - 1998 - Parallel Approximation Algorithms by Positive Linear Programming.pdf:pdf},
	Issn = {0178-4617},
	Journal = {Algorithmica},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Month = may,
	Number = {1},
	Pages = {72--88},
	Title = {{Parallel Approximation Algorithms by Positive Linear Programming}},
	Volume = {21},
	Year = {1998},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/PL00009209}}

@article{PlotkinST1995,
	Author = {Plotkin, Serge A. and Shmoys, David B. and Tardos, \'{E}va},
	Doi = {10.1287/moor.20.2.257},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Plotkin, Shmoys, Tardos - 1995 - Fast Approximation Algorithms for Fractional Packing and Covering Problems.pdf:pdf},
	Issn = {0364-765X},
	Journal = {Mathematics of Operations Research},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP},
	Month = may,
	Number = {2},
	Pages = {257--301},
	Title = {{Fast Approximation Algorithms for Fractional Packing and Covering Problems}},
	Volume = {20},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1287/moor.20.2.257}}

@article{AwerbuchKR2012,
	Author = {Awerbuch, Baruch and Khandekar, Rohit and Rao, Satish},
	Doi = {10.1145/2390176.2390179},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Awerbuch, Khandekar, Rao - 2012 - Distributed algorithms for multicommodity flow problems via approximate steepest descent framework.pdf:pdf},
	Issn = {15496325},
	Journal = {ACM Transactions on Algorithms},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/Flow},
	Month = dec,
	Number = {1},
	Pages = {1--14},
	Title = {{Distributed algorithms for multicommodity flow problems via approximate steepest descent framework}},
	Volume = {9},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2390176.2390179}}

@article{Fleischer2000,
	Author = {Fleischer, Lisa K.},
	Doi = {10.1137/S0895480199355754},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Fleischer - 2000 - Approximating Fractional Multicommodity Flow Independent of the Number of Commodities.pdf:pdf},
	Issn = {0895-4801},
	Journal = {SIAM Journal on Discrete Mathematics},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/Flow},
	Month = jan,
	Number = {4},
	Pages = {505--520},
	Title = {{Approximating Fractional Multicommodity Flow Independent of the Number of Commodities}},
	Volume = {13},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S0895480199355754}}

@article{GargK2007,
	Author = {Garg, Naveen and K\"{o}nemann, Jochen},
	Doi = {10.1137/S0097539704446232},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Garg, K\"{o}nemann - 2007 - Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems.pdf:pdf},
	Isbn = {0-8186-9172-7},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/LP,Algorithms/Multiplicative Weight/Flow},
	Month = jan,
	Number = {2},
	Pages = {630--652},
	Publisher = {IEEE Comput. Soc},
	Title = {{Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems}},
	Volume = {37},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S0097539704446232}}

@inproceedings{Madry2010,
	Address = {New York, New York, USA},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1003.5907v2},
	Author = {Madry, Aleksander},
	Booktitle = {Proceedings of the 42nd ACM symposium on Theory of computing - STOC '10},
	Doi = {10.1145/1806689.1806708},
	Eprint = {arXiv:1003.5907v2},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Madry - 2010 - Faster approximation schemes for fractional multicommodity flow problems via dynamic graph algorithms.pdf:pdf},
	Isbn = {9781450300506},
	Mendeley-Groups = {Algorithms/Multiplicative Weight/Flow},
	Pages = {121},
	Publisher = {ACM Press},
	Title = {{Faster approximation schemes for fractional multicommodity flow problems via dynamic graph algorithms}},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1806689.1806708}}

@inproceedings{Xiaodi2012,
	Author = {Gutoski, G. and Xiaodi Wu},
	Booktitle = {Computational Complexity (CCC), 2012 IEEE 27th Annual Conference on},
	Doi = {10.1109/CCC.2012.12},
	Issn = {1093-0159},
	Keywords = {approximation theory;computational complexity;game theory;mathematical programming;matrix multiplication;minimax techniques;parallel algorithms;quantum theory;theorem proving;DQIP;PSPACE;QRG(2);SQG;competing-provers complexity class;direct polynomial-space simulation;matrix multiplicative weights update method;min-max problems;multimessage quantum interactive proofs;near-optimal strategies;parallel algorithm;parallel approximation scheme;semidefinite matrices;semidefinite programs;transcript-like consistency condition;two player classical zero-sum games;two player quantum zero-sum games;Approximation methods;Bismuth;Complexity theory;Game theory;Games;Parallel algorithms;Registers;interactive proofs with competing provers;parallel approximation algorithms;semidefinite programs;zero-sum games},
	Month = {June},
	Pages = {21-31},
	Title = {Parallel Approximation of Min-max Problems with Applications to Classical and Quantum Zero-Sum Games},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/CCC.2012.12}}

@incollection{AwerbuchKhandekar2008latin,
	Author = {Awerbuch, Baruch and Khandekar, Rohit},
	Booktitle = {LATIN 2008: Theoretical Informatics},
	Pages = {580--592},
	Publisher = {Springer},
	Title = {Stateless near optimal flow control with poly-logarithmic convergence},
	Year = {2008}}

@article{AwerbuchKhandekar2009DistributedComputing,
	Author = {Awerbuch, Baruch and Khandekar, Rohit},
	Doi = {10.1007/s00446-008-0074-0},
	Issn = {0178-2770},
	Journal = {Distributed Computing},
	Keywords = {Multi-commodity flows; Distributed algorithms; Statelessness; Self-stabilization},
	Number = {5},
	Pages = {317-329},
	Publisher = {Springer-Verlag},
	Title = {Greedy distributed optimization of multi-commodity flows},
	Volume = {21},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00446-008-0074-0}}

@inproceedings{AwerbuchAzarKhandekar2008soda,
	Acmid = {1347117},
	Address = {Philadelphia, PA, USA},
	Author = {Awerbuch, Baruch and Azar, Yossi and Khandekar, Rohit},
	Booktitle = {Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
	Location = {San Francisco, California},
	Numpages = {9},
	Pages = {314--322},
	Publisher = {Society for Industrial and Applied Mathematics},
	Series = {SODA '08},
	Title = {Fast Load Balancing via Bounded Best Response},
	Year = {2008}}

@article{Nemirovski2004,
	Annote = {Nemirovski's Mirror-Prox Method},
	Author = {Nemirovski, Arkadi},
	Doi = {10.1137/S1052623403425629},
	Issn = {1052-6234},
	Journal = {SIAM Journal on Optimization},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = jan,
	Number = {1},
	Pages = {229--251},
	Title = {{Prox-Method with Rate of Convergence $O(1/t)$ for Variational Inequalities with Lipschitz Continuous Monotone Operators and Smooth Convex-Concave Saddle Point Problems}},
	Volume = {15},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S1052623403425629}}

@techreport{Shalev-Shwartz2007a,
	Annote = {Contains the detailed proof for the PEGASOS paper},
	Author = {{Shalev-Shwartz}, Shai and Singer, Yoram},
	Booktitle = {The Hebrew University, Technical \ldots},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-Shwartz, Singer - 2007 - Logarithmic regret algorithms for strongly convex repeated games.pdf:pdf},
	Institution = {The Hebrew University},
	Mendeley-Groups = {Optimization/Stochastic Online Regularized Optimization},
	Pages = {1--16},
	Title = {{Logarithmic regret algorithms for strongly convex repeated games}},
	Year = {2007}}

@phdthesis{Shalev-Shwartz2007b,
	Author = {{Shalev-Shwartz}, Shai},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shalev-Shwartz - 2007 - Online learning Theory, algorithms, and applications.pdf:pdf},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization,Optimization/General Theory},
	Number = {July},
	School = {Hebrew University},
	Title = {{Online learning: Theory, algorithms, and applications}},
	Year = {2007}}

@article{Shalev-Shwartz2011,
	Author = {{Shalev-Shwartz}, Shai},
	Doi = {10.1561/2200000018},
	Issn = {1935-8237},
	Journal = {Foundations and Trends in Machine Learning},
	Mendeley-Groups = {Optimization/Stochastic Online Regularized Optimization},
	Number = {2},
	Pages = {107--194},
	Title = {{Online Learning and Online Convex Optimization}},
	Volume = {4},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1561/2200000018}}

@inproceedings{AroraKale2007,
	Address = {New York, New York, USA},
	Author = {Arora, Sanjeev and Kale, Satyen},
	Booktitle = {Proceedings of the thirty-ninth annual ACM symposium on Theory of computing - STOC '07},
	Doi = {10.1145/1250790.1250823},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Kale - 2007 - A combinatorial, primal-dual approach to semidefinite programs.pdf:pdf},
	Isbn = {9781595936318},
	Mendeley-Groups = {Algorithms/Multiplicative Weight,Algorithms/Multiplicative Weight/SDP},
	Pages = {227},
	Publisher = {ACM Press},
	Title = {{A combinatorial, primal-dual approach to semidefinite programs}},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1250790.1250823}}

@inproceedings{AHK2005,
	Author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
	Booktitle = {46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)},
	Doi = {10.1109/SFCS.2005.35},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Hazan, Kale - 2005 - Fast Algorithms for Approximate Semidefinite Programming using the Multiplicative Weights Update Method.pdf:pdf},
	Isbn = {0-7695-2468-0},
	Mendeley-Groups = {Algorithms/Multiplicative Weight,Algorithms/Multiplicative Weight/SDP},
	Pages = {339--348},
	Publisher = {IEEE},
	Title = {{Fast Algorithms for Approximate Semidefinite Programming using the Multiplicative Weights Update Method}},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SFCS.2005.35}}

@techreport{Kakade2009,
	Author = {Kakade, Sham M. and {Shalev-Shwartz}, Shai and Tewari, Ambuj},
	Booktitle = {\ldots Manuscript, http://ttic. \ldots},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kakade, Shalev-Shwartz, Tewari - 2009 - On the duality of strong convexity and strong smoothness Learning applications and matrix regula.pdf:pdf},
	Mendeley-Groups = {Optimization/General Theory},
	Title = {{On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization}},
	Year = {2009}}

@inproceedings{KLOS2014,
	Abstract = {In this paper, we introduce a new framework for approximately solving flow problems in capacitated, undirected graphs and apply it to provide asymptotically faster algorithms for the maximum \$s\$-\$t\$ flow and maximum concurrent multicommodity flow problems. For graphs with \$n\$ vertices and \$m\$ edges, it allows us to find an \$\backslash epsilon\$-approximate maximum \$s\$-\$t\$ flow in time \$O(m\^{}\{1+o(1)\}\backslash epsilon\^{}\{-2\})\$, improving on the previous best bound of \$\backslash tilde\{O\}(mn\^{}\{1/3\} poly(1/\backslash epsilon))\$. Applying the same framework in the multicommodity setting solves a maximum concurrent multicommodity flow problem with \$k\$ commodities in \$O(m\^{}\{1+o(1)\}\backslash epsilon\^{}\{-2\}k\^{}2)\$ time, improving on the existing bound of \$\backslash tilde\{O\}(m\^{}\{4/3\} poly(k,\backslash epsilon\^{}\{-1\})\$. Our algorithms utilize several new technical tools that we believe may be of independent interest: - We give a non-Euclidean generalization of gradient descent and provide bounds on its performance. Using this, we show how to reduce approximate maximum flow and maximum concurrent flow to the efficient construction of oblivious routings with a low competitive ratio. - We define and provide an efficient construction of a new type of flow sparsifier. In addition to providing the standard properties of a cut sparsifier our construction allows for flows in the sparse graph to be routed (very efficiently) in the original graph with low congestion. - We give the first almost-linear-time construction of an \$O(m\^{}\{o(1)\})\$-competitive oblivious routing scheme. No previous such algorithm ran in time better than \$\backslash tilde\{\{\backslash Omega\}\}(mn)\$. We also note that independently Jonah Sherman produced an almost linear time algorithm for maximum flow and we thank him for coordinating submissions.},
	Archiveprefix = {arXiv},
	Arxivid = {1304.2338},
	Author = {Kelner, Jonathan A. and Lee, Yin Tat and Orecchia, Lorenzo and Sidford, Aaron},
	Booktitle = {Proceedings of the 25th Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '14},
	Doi = {10.1137/1.9781611973402.16},
	Eprint = {1304.2338},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kelner et al. - 2014 - An Almost-Linear-Time Algorithm for Approximate Max Flow in Undirected Graphs, and its Multicommodity Generalizat.pdf:pdf},
	Mendeley-Groups = {Algorithms/Maxflow},
	Month = apr,
	Number = {1},
	Series = {STOC '14},
	Title = {{An Almost-Linear-Time Algorithm for Approximate Max Flow in Undirected Graphs, and its Multicommodity Generalizations}},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/1.9781611973402.16}}

@inproceedings{LRS2013,
	Address = {New York, New York, USA},
	Author = {Lee, Yin Tat and Rao, Satish and Srivastava, Nikhil},
	Booktitle = {Proceedings of the 45th annual ACM symposium on Symposium on theory of computing - STOC '13},
	Doi = {10.1145/2488608.2488704},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Lee, Rao, Srivastava - 2013 - A new approach to computing maximum flows using electrical flows.pdf:pdf},
	Isbn = {9781450320290},
	Mendeley-Groups = {Algorithms/Maxflow},
	Pages = {755},
	Publisher = {ACM Press},
	Title = {{A new approach to computing maximum flows using electrical flows}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2488608.2488704}}

@inproceedings{Madry2013,
	Author = {Madry, Aleksander},
	Booktitle = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
	Doi = {10.1109/FOCS.2013.35},
	Isbn = {978-0-7695-5135-7},
	Mendeley-Groups = {Algorithms/Maxflow},
	Month = oct,
	Pages = {253--262},
	Publisher = {IEEE},
	Title = {{Navigating Central Path with Electrical Flows: From Flows to Matchings, and Back}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/FOCS.2013.35}}

@inproceedings{Sherman2013,
	Author = {Sherman, Jonah},
	Booktitle = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
	Doi = {10.1109/FOCS.2013.36},
	Isbn = {978-0-7695-5135-7},
	Mendeley-Groups = {Algorithms/Maxflow},
	Month = oct,
	Pages = {263--269},
	Publisher = {IEEE},
	Title = {{Nearly Maximum Flows in Nearly Linear Time}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/FOCS.2013.36}}

@inproceedings{Shalev-Shwartz2013b,
	Author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
	Booktitle = {Proceedings of the 31st International Conference on Machine Learning},
	Pages = {64--72},
	Series = {ICML 2014},
	Title = {{Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization}},
	Year = {2014}}

@inproceedings{Shalev-Shwartz2013a,
	Abstract = {Stochastic dual coordinate ascent (SDCA) is an effective technique for solving regularized loss minimization problems in machine learning. This paper considers an extension of SDCA under the mini-batch setting that is often used in practice. Our main contribution is to introduce an accelerated mini-batch version of SDCA and prove a fast convergence rate for this method. We discuss an implementation of our method over a parallel computing system, and compare the results to both the vanilla stochastic dual coordinate ascent and to the accelerated deterministic gradient descent method of $\backslash$cite\{nesterov2007gradient\}.},
	Archiveprefix = {arXiv},
	Arxivid = {1305.2581},
	Author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
	Booktitle = {NIPS},
	Eprint = {1305.2581},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-Shwartz, Zhang - 2013 - Accelerated Mini-Batch Stochastic Dual Coordinate Ascent.pdf:pdf},
	Mendeley-Groups = {Optimization/Stochastic Online Regularized Optimization},
	Month = may,
	Pages = {1--17},
	Title = {{Accelerated Mini-Batch Stochastic Dual Coordinate Ascent}},
	Year = {2013}}

@article{Shalev-Shwartz2015-SDCAwithoutDual,
	Archiveprefix = {arXiv},
	Arxivid = {1502.06177},
	Author = {{Shalev-Shwartz}, Shai},
	Eprint = {1502.06177},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-Shwartz - 2015 - SDCA without Duality.pdf:pdf},
	Journal = {arXiv preprint arXiv:1502.06177},
	Mendeley-Groups = {Optimization/[with Yuan Yang],Optimization/Stochastic Online Optimization},
	Pages = {1--7},
	Title = {{SDCA without Duality}},
	Url = {http://arxiv.org/pdf/1502.06177v1.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1502.06177v1.pdf}}

@article{Shalev-ShwartzZhang2014-ProxSDCA,
	Archiveprefix = {arXiv},
	Arxivid = {1211.2717},
	Author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
	Eprint = {1211.2717},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-shwartz, Zhang - 2012 - Proximal Stochastic Dual Coordinate Ascent.pdf:pdf},
	Journal = {arXiv preprint arXiv:1211.2717},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Pages = {1--18},
	Title = {{Proximal Stochastic Dual Coordinate Ascent}},
	Url = {http://arxiv.org/pdf/1211.2717v1.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1211.2717v1.pdf}}

@techreport{BienstockIyengar2004,
	Author = {Bienstock, D. and Iyengar, G.},
	Note = {Preliminary version published in STOC '04},
	Title = {{Faster approximation algorithms for packing and covering problems}},
	Year = {2004}}

@article{Dekel2012,
	Abstract = {Online prediction methods are typically presented as serial algorithms running on a single processor. However, in the age of web-scale prediction problems, it is increasingly common to encounter situations where a single processor cannot keep up with the high rate at which inputs arrive. In this work, we present the $\backslash$emph\{distributed mini-batch\} algorithm, a method of converting many serial gradient-based online prediction algorithms into distributed algorithms. We prove a regret bound for this method that is asymptotically optimal for smooth convex loss functions and stochastic inputs. Moreover, our analysis explicitly takes into account communication latencies between nodes in the distributed environment. We show how our method can be used to solve the closely-related distributed stochastic optimization problem, achieving an asymptotically linear speed-up over multiple processors. Finally, we demonstrate the merits of our approach on a web-scale online prediction problem.},
	Annote = {Contains some information about "using mirror descent steps" on smooth objectives, though analyzed in stochastic way.},
	Archiveprefix = {arXiv},
	Arxivid = {1012.1367},
	Author = {Dekel, Ofer and {Gilad-Bachrach}, Ran and Shamir, Ohad and Xiao, Lin},
	Eprint = {1012.1367},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Dekel et al. - 2012 - Optimal distributed online prediction using mini-batches.pdf:pdf},
	Isbn = {978-1-4503-0619-5},
	Issn = {1532-4435},
	Journal = {The Journal of Machine Learning Research},
	Keywords = {convex,distributed computing,online learning,regret bounds,stochastic optimization},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Number = {1},
	Pages = {165--202},
	Title = {{Optimal distributed online prediction using mini-batches}},
	Volume = {13},
	Year = {2012}}

@inproceedings{zurel2001efficient,
	Author = {Zurel, Edo and Nisan, Noam},
	Booktitle = {Proceedings of the 3rd ACM conference on Electronic Commerce},
	Organization = {ACM},
	Pages = {125--136},
	Title = {An efficient approximate allocation algorithm for combinatorial auctions},
	Year = {2001}}

@inproceedings{byers2000utility,
	Author = {Byers, John and Nasser, Gabriel},
	Booktitle = {Mobile and Ad Hoc Networking and Computing, 2000. MobiHOC. 2000 First Annual Workshop on},
	Organization = {IEEE},
	Pages = {143--144},
	Title = {Utility-based decision-making in wireless sensor networks},
	Year = {2000}}

@article{kivinen1997exponentiated,
	Author = {Kivinen, Jyrki and Warmuth, Manfred K},
	Journal = {Information and Computation},
	Number = {1},
	Pages = {1--63},
	Publisher = {Elsevier},
	Title = {Exponentiated gradient versus gradient descent for linear predictors},
	Volume = {132},
	Year = {1997}}

@inproceedings{ShamirZhang2013,
	Abstract = {Stochastic Gradient Descent (SGD) is one of the simplest and most popular stochastic optimization methods. While it has already been theoretically studied for decades, the classical analysis usually required non-trivial smoothness assumptions, which do not apply to many modern applications of SGD with non-smooth objective functions such as support vector machines. In this paper, we investigate the performance of SGD without such smoothness assumptions, as well as a running average scheme to convert the SGD iterates to a solution with optimal optimization accuracy. In this framework, we prove that after T rounds, the suboptimality of the last SGD iterate scales as O(log(T)/$\backslash$sqrt\{T\}) for non-smooth convex objective functions, and O(log(T)/T) in the non-smooth strongly convex case. To the best of our knowledge, these are the first bounds of this kind, and almost match the minimax-optimal rates obtainable by appropriate averaging schemes. We also propose a new and simple averaging scheme, which not only attains optimal rates, but can also be easily computed on-the-fly (in contrast, the suffix averaging scheme proposed in Rakhlin et al. (2011) is not as simple to implement). Finally, we provide some experimental illustrations.},
	Annote = {This paper answers the open question of Shamir in COLT'12 about how to get a non-smooth algorithm whose last round is great, rather than avearging of the history. This paper also works for strongly-convex non-smooth functions.},
	Archiveprefix = {arXiv},
	Arxivid = {1212.1824},
	Author = {Shamir, Ohad and Zhang, Tong},
	Booktitle = {Proceedings of the 30th International Conference on Machine Learning - ICML '13},
	Eprint = {1212.1824},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shamir, Zhang - 2013 - Stochastic Gradient Descent for Non-smooth Optimization Convergence Results and Optimal Averaging Schemes.pdf:pdf},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Title = {{Stochastic Gradient Descent for Non-smooth Optimization: Convergence Results and Optimal Averaging Schemes}},
	Volume = {28},
	Year = {2013}}

@article{Fercoq2013,
	Author = {Fercoq, Olivier and Richt\'{a}rik, Peter},
	Journal = {SIAM Journal on Optimization},
	Note = {First appeared on ArXiv 1312.5799 in 2013},
	Number = {4},
	Pages = {1997-2023},
	Title = {Accelerated, Parallel, and Proximal Coordinate Descent},
	Volume = {25},
	Year = {2015}}

@article{ODonoghue2012,
	Author = {{O'Donoghue}, Brendan and Cand\`{e}s, Emmanuel},
	Doi = {10.1007/s10208-013-9150-3},
	File = {:C$\backslash$:/Users/Zeyuan Zhu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title.pdf:pdf},
	Issn = {1615-3375},
	Journal = {Foundations of Computational Mathematics},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = jul,
	Title = {{Adaptive Restart for Accelerated Gradient Schemes}},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10208-013-9150-3}}

@article{BLS2015,
	Author = {Bubeck, S{\'e}bastien and Lee, Yin Tat and Singh, Mohit},
	Journal = {ArXiv e-prints},
	Month = jun,
	Title = {A geometric alternative to {N}esterov's accelerated gradient descent},
	Url = {http://arxiv.org/abs/1506.08187},
	Volume = {abs/1506.08187},
	Year = 2015,
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.08187}}

@inproceedings{freund1995desicion,
	Author = {Freund, Yoav and Schapire, Robert E},
	Booktitle = {Computational learning theory},
	Organization = {Springer},
	Pages = {23--37},
	Title = {A desicion-theoretic generalization of on-line learning and an application to boosting},
	Year = {1995}}

@article{McMahan2011,
	Abstract = {We study three families of online convex optimization algorithms: follow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual averaging (RDA), and composite-objective mirror descent. We first prove equivalence theorems that show all of these algorithms are instantiations of a general FTRL update. This provides theoretical insight on previous experimental observations. In particular, even though the FOBOS composite mirror descent algorithm handles L1 regularization explicitly, it has been observed that RDA is even more effective at producing sparsity. Our results demonstrate that FOBOS uses subgradient approximations to the L1 penalty from previous rounds, leading to less sparsity than RDA, which handles the cumulative penalty in closed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two, and outperforms both on a large, real-world dataset. Our second contribution is a unified analysis which produces regret bounds that match (up to logarithmic terms) or improve the best previously known bounds. This analysis also extends these algorithms in two important ways: we support a more general type of composite objective and we analyze implicit updates, which replace the subgradient approximation of the current loss function with an exact optimization.},
	Annote = {This is presumably the journal version of "Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization"
      },
	Archiveprefix = {arXiv},
	Arxivid = {1009.3240},
	Author = {McMahan, H. Brendan},
	Eprint = {1009.3240},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/McMahan - 2011 - A Unified View of Regularized Dual Averaging and Mirror Descent with Implicit Updates.pdf:pdf},
	Journal = {arXiv preprint arXiv:1009.3240},
	Keywords = {bounds,follow-the-leader algorithms,online convex optimization,online learning,regret,subgradient methods},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = sep,
	Note = {Previously appeared in AISTATS 2011 as a conference paper entitled ``{Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization}''},
	Title = {{A Unified View of Regularized Dual Averaging and Mirror Descent with Implicit Updates}},
	Year = {2011}}

@inproceedings{McMahanStreeter2010,
	Abstract = {We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm's regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight.},
	Archiveprefix = {arXiv},
	Arxivid = {1002.4908},
	Author = {McMahan, H. Brendan and Streeter, Matthew},
	Booktitle = {Proceedings of the 23rd Annual Conference on Learning Theory - COLT '10},
	Eprint = {1002.4908},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = feb,
	Title = {{Adaptive Bound Optimization for Online Convex Optimization}},
	Year = {2010}}

@inproceedings{Duchi2010,
	Abstract = {We present a new method for regularized convex optimization and analyze it under both online and stochastic optimization settings. In addition to unifying previously known firstorder algorithms, such as the projected gradient method, mirror descent, and forwardbackward splitting, our method yields new analysis and algorithms. We also derive specific instantiations of our method for commonly used regularization functions, such as ℓ1, mixed norm, and trace-norm.},
	Author = {Duchi, John and {Shalev-Shwartz}, Shai and Singer, Yoram and Tewari, Ambuj},
	Booktitle = {Proceedings of the 23rd Annual Conference on Learning Theory - COLT '10},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Duchi et al. - 2010 - Composite Objective Mirror Descent.pdf:pdf},
	Keywords = {Learning/Statistics \& Optimisation,Theory \& Algorithms},
	Mendeley-Groups = {Optimization/Gradient Descent Theory/Composite},
	Number = {1},
	Title = {{Composite Objective Mirror Descent}},
	Year = {2010}}

@article{Nesterov2013,
	Author = {Nesterov, Yurii},
	Doi = {10.1007/s10107-012-0629-5},
	File = {:D$\backslash$:/Mendeley Desktop/Nesterov - 2013 - Gradient methods for minimizing composite functions.pdf:pdf},
	Issn = {0025-5610},
	Journal = {Mathematical Programming},
	Mendeley-Groups = {Optimization/Gradient Descent Theory,Optimization/Gradient Descent Theory/Composite},
	Number = {1},
	Pages = {125--161},
	Title = {{Gradient methods for minimizing composite functions}},
	Volume = {140},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10107-012-0629-5}}

@article{Lan2011,
	Author = {Lan, Guanghui},
	Doi = {10.1007/s10107-010-0434-y},
	File = {:D$\backslash$:/Mendeley Desktop/Lan - 2011 - An optimal method for stochastic composite optimization.pdf:pdf},
	Isbn = {0001408100},
	Issn = {0025-5610},
	Journal = {Mathematical Programming},
	Keywords = {convex optimization,stochastic approximation},
	Mendeley-Groups = {Optimization/Gradient Descent Theory/Composite},
	Month = jan,
	Number = {1-2},
	Pages = {365--397},
	Title = {{An optimal method for stochastic composite optimization}},
	Volume = {133},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10107-010-0434-y}}

@article{nesterov2008cubic,
	Author = {Nesterov, Yurii},
	Journal = {Mathematical Programming},
	Number = {1},
	Pages = {159--181},
	Publisher = {Springer},
	Title = {Accelerating the cubic regularization of Newton's method on convex problems},
	Volume = {112},
	Year = {2008}}

@article{Nesterov2014,
	Author = {Nesterov, Yurii},
	Doi = {10.1007/s10107-014-0790-0},
	Issn = {0025-5610},
	Journal = {Mathematical Programming},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = may,
	Title = {{Universal gradient methods for convex optimization problems}},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10107-014-0790-0}}

@article{Xiao2010,
	Annote = {Contains the so-called "dual averaging" step.},
	Author = {Xiao, Lin},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Xiao - 2010 - Dual averaging method for regularized stochastic learning and online optimization.pdf:pdf},
	Journal = {The Journal of Machine Learning Research},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Pages = {2543--2596},
	Title = {{Dual averaging method for regularized stochastic learning and online optimization}},
	Volume = {11},
	Year = {2010}}

@article{banerjee2005clustering,
	Author = {Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S. and Ghosh, Joydeep},
	Journal = {The Journal of Machine Learning Research},
	Pages = {1705--1749},
	Publisher = {JMLR. org},
	Title = {Clustering with Bregman divergences},
	Volume = {6},
	Year = {2005}}

@book{Rockafellar1996convex,
	Author = {Rockafellar, R. Tyrrell},
	Publisher = {Princeton University Press},
	Title = {Convex Analysis (Princeton Landmarks in Mathematics and Physics)},
	Year = {1996}}

@inproceedings{Auer1995,
	Author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Freund, Yoav and Schapire, Robert E.},
	Booktitle = {Proceedings of IEEE 36th Annual Foundations of Computer Science},
	Doi = {10.1109/SFCS.1995.492488},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Gambling in a rigged casino The adversarial multi-armed bandit problem.pdf:pdf},
	Isbn = {0-8186-7183-1},
	Mendeley-Groups = {Optimization/Bandit},
	Pages = {322--331},
	Publisher = {IEEE Comput. Soc. Press},
	Title = {{Gambling in a rigged casino: The adversarial multi-armed bandit problem}},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SFCS.1995.492488}}

@article{Auer2002nonstochastic,
	Author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Freund, Yoav and Schapire, Robert E.},
	Doi = {10.1137/S0097539701398375},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/7c440d389dadd89e5dc4f71b705d5fb816b5cad6.pdf:pdf},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Keywords = {1995,331,68q32 68t05 91a20,adversarial bandit problem,ams subject classification,an early extended abstract,in the proceedings of,of this paper appeared,on founda-,pages 322,the 36th annual symposium,tions of computer science,unknown matrix games},
	Mendeley-Groups = {Optimization/Bandit},
	Month = jan,
	Note = {The journal version of Auer et al. 1995},
	Number = {1},
	Pages = {48--77},
	Title = {{The Nonstochastic Multiarmed Bandit Problem}},
	Volume = {32},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S0097539701398375}}

@book{Cesa-Bianchi2006,
	Address = {Cambridge},
	Author = {{Cesa-Bianchi}, Nicolo and Lugosi, Gabor},
	Doi = {10.1017/CBO9780511546921},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cesa-Bianchi, Lugosi - 2006 - Prediction, Learning, and Games.pdf:pdf},
	Isbn = {9780511546921},
	Mendeley-Groups = {Books/Optimization},
	Publisher = {Cambridge University Press},
	Title = {{Prediction, Learning, and Games}},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/CBO9780511546921}}

@inproceedings{AbernethyRakhlin2009,
	Abstract = {We provide a principled way of proving Omacr(radicT) high-probability guarantees for partial-information (bandit) problems over arbitrary convex decision sets. First, we prove a regret guarantee for the full-information problem in terms of ldquolocalrdquo norms, both for entropy and self-concordant barrier regularization, unifying these methods. Given one of such algorithms as a black-box, we can convert a bandit problem into a full-information problem using a sampling scheme. The main result states that a high-probability Omacr(radicT) bound holds whenever the black-box, the sampling scheme, and the estimates of missing information satisfy a number of conditions, which are relatively easy to check. At the heart of the method is a construction of linear upper bounds on confidence intervals. As applications of the main result, we provide the first known efficient algorithm for the sphere with an Omacr(radicT) high-probability bound. We also derive the result for the n-simplex, improving the O(radicnT log(nT)) bound of Auer et al [3] by replacing the log T term with log log T and closing the gap to the lower bound of Omacr(radicnT). While Omacr(radicT) high-probability bounds should hold for general decision sets through our main result, construction of linear upper bounds depends on the particular geometry of the set; we believe that the sphere example already exhibits the necessary ingredients. The guarantees we obtain hold for adaptive adversaries (unlike the in-expectation results of [1]) and the algorithms are efficient, given that the linear upper bounds on confidence can be computed.},
	Author = {Abernethy, Jacob and Rakhlin, Alexander},
	Booktitle = {Proceedings of the 22nd Conference on Learning Theory - COLT' 09},
	Doi = {10.1109/ITA.2009.5044958},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abernethy, Rakhlin - 2009 - Beating the adaptive bandit with high probability.pdf:pdf},
	Isbn = {9781424439904},
	Mendeley-Groups = {Optimization/Bandit},
	Pages = {280--289},
	Title = {{Beating the adaptive bandit with high probability}},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ITA.2009.5044958}}

@inproceedings{BDHKRT2008,
	Author = {Bartlett, Peter L. and Dani, Varsha and Hayes, Thomas P. and Kakade, Sham M. and Rakhlin, Alexander and Tewari, Ambuj},
	Booktitle = {Proceedings of the 21st Conference on Learning Theory - COLT '08},
	File = {:D$\backslash$:/Mendeley Desktop/Bartlett et al. - 2008 - High-probability regret bounds for bandit online linear optimization.pdf:pdf},
	Mendeley-Groups = {Optimization/Bandit},
	Title = {{High-probability regret bounds for bandit online linear optimization}},
	Year = {2008}}

@article{robbins1952some,
	Author = {Robbins, Herbert},
	Journal = {Bulletin of the American Mathematical Society},
	Pages = {527--535},
	Title = {Some Aspects of the Sequential Design of Experiments},
	Volume = {58},
	Year = {1952}}

@inproceedings{Kleinberg2003,
	Abstract = {We consider price-setting algorithms for a simple market in which a seller has an unlimited supply of identical copies of some good, and interacts sequentially with a pool of n buyers, each of whom wants at most one copy of the good. In each transaction, the seller offers a price between 0 and 1, and the buyer decides whether or not to buy, by comparing the offered price to his privately-held valuation for the good. The price offered to a given buyer may be influenced by the outcomes of prior transactions, but each individual buyer participates only once. In this setting, what is the value of knowing the demand curve? In other words, how much revenue can an uninformed seller expect to obtain, relative to a seller with prior information about the buyers' valuations? The answer depends on how the buyers' valuations are modeled. We analyze three cases - identical, random, and worst-case valuations - in each case deriving upper and lower bounds which match within a sublogarithmic factor.},
	Author = {Kleinberg, R. and Leighton, T.},
	Booktitle = {44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings.},
	Doi = {10.1109/SFCS.2003.1238232},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(2).pdf:pdf},
	Isbn = {0-7695-2040-5},
	Issn = {0272-5428},
	Mendeley-Groups = {Operation Research},
	Number = {Focs 2003},
	Pages = {594--605},
	Publisher = {IEEE Computer. Soc},
	Title = {{The value of knowing a demand curve: bounds on regret for online posted-price auctions}},
	Year = {2003},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SFCS.2003.1238232}}

@book{berry1985bandit,
	Author = {Berry, Donald A and Fristedt, Bert},
	Publisher = {Springer},
	Title = {Bandit Problems: Sequential Allocation of Experiments (Monographs on Statistics and Applied Probability)},
	Year = {1985}}

@article{veatch1996scheduling,
	Author = {Veatch, Michael H and Wein, Lawrence M},
	Journal = {Operations Research},
	Number = {4},
	Pages = {634--647},
	Publisher = {INFORMS},
	Title = {Scheduling a make-to-stock queue: Index policies and hedging points},
	Volume = {44},
	Year = {1996}}

@article{whittle1988restless,
	Author = {Whittle, Peter},
	Journal = {Journal of applied probability},
	Pages = {287--298},
	Publisher = {JSTOR},
	Title = {Restless bandits: Activity allocation in a changing world},
	Year = {1988}}

@inproceedings{radlinski2008learning,
	Author = {Radlinski, Filip and Kleinberg, Robert and Joachims, Thorsten},
	Booktitle = {Proceedings of the 25th international conference on Machine learning},
	Organization = {ACM},
	Pages = {784--791},
	Title = {Learning diverse rankings with multi-armed bandits},
	Year = {2008}}

@inproceedings{awerbuch2004adaptive,
	Author = {Awerbuch, Baruch and Kleinberg, Robert D},
	Booktitle = {Proceedings of the thirty-sixth annual ACM symposium on Theory of computing},
	Organization = {ACM},
	Pages = {45--53},
	Title = {Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches},
	Year = {2004}}

@article{gyorgy2007line,
	Author = {Gy{\"o}rgy, Andr{\'a}s and Linder, Tam{\'a}s and Lugosi, G{\'a}bor and Ottucs{\'a}k, Gy{\"o}rgy},
	Journal = {Journal of Machine Learning Research},
	Pages = {2369--2403},
	Title = {The On-Line Shortest Path Problem Under Partial Monitoring},
	Volume = {8},
	Year = {2007}}

@article{Auer2002stochastic,
	Annote = {This is for the case when there is a fixed (but unknown) distribution where the feedbacks are generated.

It is different from the other type of bandit work where there is no distribution.},
	Author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Fischer, Paul},
	Doi = {10.1023/A:1013689704352},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Auer, Cesa-Bianchi, Fischer - 2002 - Finite-time analysis of the multiarmed bandit problem.pdf:pdf},
	Journal = {Machine Learning},
	Mendeley-Groups = {Optimization/Bandit},
	Number = {2-3},
	Pages = {235--256},
	Title = {{Finite-time analysis of the multiarmed bandit problem}},
	Volume = {47},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1013689704352}}

@article{Abernethy2012,
	Author = {Abernethy, Jacob D. and Hazan, Elad and Rakhlin, Alexander},
	Doi = {10.1109/TIT.2012.2192096},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abernethy, Hazan, Rakhlin - 2012 - Interior-Point Methods for Full-Information and Bandit Online Learning.pdf:pdf},
	Issn = {0018-9448},
	Journal = {IEEE Transactions on Information Theory},
	Mendeley-Groups = {Optimization/Bandit},
	Month = jul,
	Note = {An earlier version of this paper has appeared in COLT'08},
	Number = {7},
	Pages = {4164--4175},
	Title = {{Interior-Point Methods for Full-Information and Bandit Online Learning}},
	Volume = {58},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/TIT.2012.2192096}}

@inproceedings{mcmahan2004online,
	Author = {McMahan, H Brendan and Blum, Avrim},
	Booktitle = {COLT 2004},
	Organization = {Springer},
	Pages = {109},
	Title = {Online Geometric Optimization in the Bandit Setting Against an Adaptive Adversary},
	Volume = {17},
	Year = {2004}}

@inproceedings{flaxman2005online,
	Author = {Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
	Booktitle = {Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms},
	Organization = {Society for Industrial and Applied Mathematics},
	Pages = {385--394},
	Title = {Online convex optimization in the bandit setting: gradient descent without a gradient},
	Year = {2005}}

@inproceedings{dani2007price,
	Author = {Dani, Varsha and Kakade, Sham M and Hayes, Thomas P},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {345--352},
	Title = {The price of bandit information for online optimization},
	Year = {2007}}

@article{bartlett2008high,
	Author = {Bartlett, Peter L and Dani, Varsha and Hayes, Thomas and Kakade, Sham and Rakhlin, Alexander and Tewari, Ambuj},
	Booktitle = {COLT 2008},
	Title = {High-probability regret bounds for bandit online linear optimization},
	Year = {2008}}

@inproceedings{babaioff2009characterizing,
	Author = {Babaioff, Moshe and Sharma, Yogeshwer and Slivkins, Aleksandrs},
	Booktitle = {Proceedings of the 10th ACM conference on Electronic commerce},
	Organization = {ACM},
	Pages = {79--88},
	Title = {Characterizing truthful multi-armed bandit mechanisms},
	Year = {2009}}

@article{rakhlin2009lecture,
	Author = {Rakhlin, Alexander},
	Journal = {Draft},
	Note = {Available at \url{http://www-stat.wharton.upenn.edu/~rakhlin/courses/stat991/papers/lecture_notes.pdf}},
	Title = {Lecture notes on online learning},
	Year = {2009}}

@inproceedings{zinkevich2003online,
	Author = {Zinkevich, Martin},
	Booktitle = {Proceedings of the 20th International Conference on Machine Learning},
	Pages = {928--936},
	Series = {ICML 2003},
	Title = {Online Convex Programming and Generalized Infinitesimal Gradient Ascent},
	Year = {2003}}

@book{barto1998reinforcement,
	Author = {Barto, Andrew G},
	Publisher = {MIT press},
	Title = {Reinforcement learning: An introduction},
	Year = {1998}}

@article{Young14,
	Author = {Neal E. Young},
	Journal = {ArXiv e-prints},
	Month = jul,
	Title = {Nearly Linear-Time Approximation Schemes for Mixed Packing/Covering and Facility-Location Linear Programs},
	Url = {http://arxiv.org/abs/1407.3015},
	Volume = {abs/1407.3015},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1407.3015}}

@inproceedings{KOSZ13,
	Author = {Jonathan A. Kelner and Lorenzo Orecchia and Aaron Sidford and Zeyuan Allen Zhu},
	Booktitle = {Proceedings of the 45th Annual ACM Symposium on Theory of Computing},
	Series = {STOC~'13},
	Title = {A Simple, Combinatorial Algorithm for Solving {SDD} Systems in Nearly-{L}inear Time},
	Year = {2013}}

@article{Lieb1973convex,
	Author = {Lieb, Elliott H.},
	Journal = {Advances in Mathematics},
	Number = {3},
	Pages = {267--288},
	Publisher = {Elsevier},
	Title = {Convex trace functions and the Wigner-Yanase-Dyson conjecture},
	Volume = {11},
	Year = {1973}}

@article{SpielmanSrivastava2011,
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:0803.0929v4},
	Author = {Spielman, Daniel A. and Srivastava, Nikhil},
	Doi = {10.1137/080734029},
	Eprint = {arXiv:0803.0929v4},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman - 2009 - Graph Sparsification by Effective Resistances ∗.pdf:pdf},
	Issn = {0097-5397},
	Journal = {SIAM Journal on Computing},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = jan,
	Number = {6},
	Pages = {1913--1926},
	Title = {{Graph Sparsification by Effective Resistances}},
	Volume = {40},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/080734029}}

@article{BSS2009,
	Abstract = {We prove that every graph has a spectral sparsifier with a number of edges linear in its number of vertices. As linear-sized spectral sparsifiers of complete graphs are expanders, our sparsifiers of arbitrary graphs can be viewed as generalizations of expander graphs. In particular, we prove that for every \$d>1\$ and every undirected, weighted graph \$G=(V,E,w)\$ on \$n\$ vertices, there exists a weighted graph \$H=(V,F,\backslash tilde\{w\})\$ with at most \$\backslash ceil\{d(n-1)\}\$ edges such that for every \$x \backslash in \backslash R\^{}\{V\}\$, $\backslash$[ x\^{}\{T\}L\_\{G\}x $\backslash$leq x\^{}\{T\}L\_\{H\}x $\backslash$leq ($\backslash$frac\{d+1+2$\backslash$sqrt\{d\}\}\{d+1-2$\backslash$sqrt\{d\}\})$\backslash$cdot x\^{}\{T\}L\_\{G\}x $\backslash$] where \$L\_\{G\}\$ and \$L\_\{H\}\$ are the Laplacian matrices of \$G\$ and \$H\$, respectively. Thus, \$H\$ approximates \$G\$ spectrally at least as well as a Ramanujan expander with \$dn/2\$ edges approximates the complete graph. We give an elementary deterministic polynomial time algorithm for constructing \$H\$.},
	Address = {New York, New York, USA},
	Archiveprefix = {arXiv},
	Arxivid = {0808.0163},
	Author = {Batson, Joshua and Spielman, Daniel A. and Srivastava, Nikhil},
	Doi = {10.1137/130949117},
	Eprint = {0808.0163},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Batson, Spielman, Srivastava - 2009 - Twice-\{R\}amanujan Sparsifiers.pdf:pdf},
	Isbn = {9781605585062},
	Issn = {0036-1445},
	Journal = {SIAM Review},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = may,
	Number = {2},
	Pages = {315--334},
	Publisher = {ACM Press},
	Title = {{Twice-Ramanujan Sparsifiers}},
	Volume = {56},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/130949117}}

@techreport{Silva2011,
	Abstract = {Recently there has been much interest in "sparsifying" sums of rank one matrices: modifying the coefficients such that only a few are nonzero, while approximately preserving the matrix that results from the sum. Results of this sort have found applications in many different areas, including sparsifying graphs. In this paper we consider the more general problem of sparsifying sums of positive semidefinite matrices that have arbitrary rank. We give several algorithms for solving this problem. The first algorithm is based on the method of Batson, Spielman and Srivastava (2009). The second algorithm is based on the matrix multiplicative weights update method of Arora and Kale (2007). We also highlight an interesting connection between these two algorithms. Our algorithms have numerous applications. We show how they can be used to construct graph sparsifiers with auxiliary constraints, sparsifiers of hypergraphs, and sparse solutions to semidefinite programs.},
	Archiveprefix = {arXiv},
	Arxivid = {1107.0088},
	Author = {{\noopsort{Carli Silva}}de {Carli Silva}, Marcel K. and Harvey, Nicholas J. A. and Sato, Cristiane M.},
	Eprint = {1107.0088},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva, Harvey, Sato - 2011 - Sparse Sums of Positive Semidefinite Matrices(2).pdf:pdf},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = jul,
	Title = {{Sparse Sums of Positive Semidefinite Matrices}},
	Year = {2011}}

@article{JL1984,
	Author = {Johnson, William B. and Lindenstrauss, Joram},
	Doi = {10.1090/conm/026/737400},
	Journal = {Contemporary Mathematics},
	Mendeley-Groups = {Algorithms/Sublinear Algorithms/JL},
	Pages = {189--206},
	Title = {{Extensions of Lipschitz mappings into a Hilbert space}},
	Volume = {26},
	Year = {1984},
	Bdsk-Url-1 = {http://dx.doi.org/10.1090/conm/026/737400}}

@inproceedings{Bansal2011,
	Abstract = {We study graph partitioning problems from a min-max perspective, in which an input graph on n vertices should be partitioned into k parts, and the objective is to minimize the maximum number of edges leaving a single part. The two main versions we consider are where the k parts need to be of equal-size, and where they must separate a set of k given terminals. We consider a common generalization of these two problems, and design for it an \$O(\backslash sqrt\{\backslash log n\backslash log k\})\$-approximation algorithm. This improves over an \$O(\backslash log\^{}2 n)\$ approximation for the second version, and roughly \$O(k\backslash log n)\$ approximation for the first version that follows from other previous work. We also give an improved O(1)-approximation algorithm for graphs that exclude any fixed minor. Our algorithm uses a new procedure for solving the Small-Set Expansion problem. In this problem, we are given a graph G and the goal is to find a non-empty set \$S\backslash subseteq V\$ of size \$|S| \backslash leq \backslash rho n\$ with minimum edge-expansion. We give an \$O(\backslash sqrt\{\backslash log\{n\}\backslash log\{(1/\backslash rho)\}\})\$ bicriteria approximation algorithm for the general case of Small-Set Expansion, and O(1) approximation algorithm for graphs that exclude any fixed minor.},
	Archiveprefix = {arXiv},
	Arxivid = {1110.4319},
	Author = {Bansal, Nikhil and Feige, Uriel and Krauthgamer, Robert and Makarychev, Konstantin and Nagarajan, Viswanath and Naor, Joseph (Seffi) and Schwartz, Roy},
	Booktitle = {2011 IEEE 52nd Annual Symposium on Foundations of Computer Science},
	Doi = {10.1109/FOCS.2011.79},
	Eprint = {1110.4319},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bansal et al. - 2011 - Min-max Graph Partitioning and Small Set Expansion.pdf:pdf},
	Isbn = {978-0-7695-4571-4},
	Mendeley-Groups = {Algorithms/Sparsest Cut,Algorithms/Small Set Expansion,Algorithms/Sparsest Cut/SSE},
	Month = oct,
	Pages = {17--26},
	Publisher = {IEEE},
	Title = {{Min-max Graph Partitioning and Small Set Expansion}},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/FOCS.2011.79}}

@inproceedings{Asadpour2010,
	Author = {Asadpour, Arash and Goemans, Michel X. and M{\k a}dry, Aleksander and Gharan, Shayan Oveis and Saberi, Amin},
	Booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '10},
	File = {:D$\backslash$:/Mendeley Desktop/Asadpour et al. - 2010 - An O ( log n log log n ) -approximation Algorithm for the Asymmetric Traveling Salesman Problem.pdf:pdf},
	Isbn = {0001405101},
	Mendeley-Groups = {Algorithms/Traveling Salesman},
	Pages = {379--389},
	Title = {{An $O(\log n / \log \log n )$-approximation Algorithm for the Asymmetric Traveling Salesman Problem}},
	Year = {2010}}

@inproceedings{Daskalakis2011,
	Author = {Daskalakis, Constantinos and Deckelbaum, Alan and Kim, Anthony},
	Booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '11},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Daskalakis, Deckelbaum, Kim - 2011 - Near-optimal no-regret algorithms for zero-sum games.pdf:pdf},
	Mendeley-Groups = {Game Theory/Zero-sum Games},
	Pages = {235--254},
	Title = {{Near-optimal no-regret algorithms for zero-sum games}},
	Year = {2011}}

@inproceedings{Steurer2010,
	Author = {Steurer, David},
	Booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '10},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steurer - 2010 - Fast SDP algorithms for constraint satisfaction problems.pdf:pdf},
	Mendeley-Groups = {Optimization/Multiplicative Weight/SDP},
	Pages = {684----697},
	Title = {{Fast SDP algorithms for constraint satisfaction problems}},
	Year = {2010}}

@article{audibert2011minimax,
	Author = {Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Lugosi, G{\'a}bor},
	Journal = {Proceedings of COLT 2011},
	Title = {Minimax Policies for Combinatorial Prediction Games},
	Year = {2011}}

@phdthesis{Orecchia11,
	Author = {Orecchia, Lorenzo},
	Month = {May},
	Number = {UCB/EECS-2011-56},
	School = {EECS Department, University of California, Berkeley},
	Title = {Fast Approximation Algorithms for Graph Partitioning using Spectral and Semidefinite-Programming Techniques},
	Year = {2011}}

@techreport{BenczurKarger02,
	Archiveprefix = {arXiv},
	Arxivid = {cs/0207078},
	Author = {Bencz\'{u}r, Andr\'{a}s A. and Karger, David R.},
	Booktitle = {arXiv preprint cs/0207078},
	Eprint = {0207078},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/110a03446ced34ac8baaf80534e7433c45797196.pdf:pdf},
	Mendeley-Groups = {Algorithms/Sparsification},
	Month = jul,
	Pages = {1--20},
	Primaryclass = {cs},
	Title = {{Randomized Approximation Schemes for Cuts and Flows in Capacitated Graphs}},
	Year = {2002}}

@inproceedings{BenczurKarger96,
	Address = {New York, New York, USA},
	Author = {Bencz\'{u}r, Andr\'{a}s A. and Karger, David R.},
	Booktitle = {Proceedings of the twenty-eighth annual ACM symposium on Theory of computing - STOC '96},
	Doi = {10.1145/237814.237827},
	Isbn = {0897917855},
	Mendeley-Groups = {Algorithms/Sparsification},
	Pages = {47--55},
	Publisher = {ACM Press},
	Title = {{Approximating s-t minimum cuts in $\tilde{O}(n^2)$ time}},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/237814.237827}}

@article{bubeck2012regret,
	Author = {Bubeck, S{\'e}bastien and {Cesa-Bianchi}, Nicolo},
	Journal = {Foundations and trends in machine learning},
	Number = {1},
	Pages = {1--122},
	Publisher = {Now Publisher},
	Title = {Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
	Volume = {5},
	Year = {2012}}

@article{Anderson2014,
	Author = {Anderson, David G. and Gu, Ming and Melgaard, Christopher},
	Eprint = {1410.4273},
	Journal = {ArXiv e-prints},
	Month = oct,
	Title = {{An Efficient Algorithm for Unweighted Spectral Graph Sparsification}},
	Url = {http://arxiv.org/abs/1410.4273v1},
	Volume = {abs/1410.4273},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1410.4273v1}}

@incollection{KleinYoung99,
	Author = {Klein, Philip and Young, Neal},
	Booktitle = {Integer Programming and Combinatorial Optimization},
	Doi = {10.1007/3-540-48777-8_24},
	Editor = {Cornu\'{e}jols, G\'{e}rard and Burkard, Rainer E. and Woeginger, Gerhard J.},
	Isbn = {978-3-540-66019-4},
	Pages = {320-327},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {On the Number of Iterations for Dantzig-Wolfe Optimization and Packing-Covering Approximation Algorithms},
	Volume = {1610},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-48777-8_24}}

@article{Shalev-Shwartz2011a,
	Author = {{Shalev-Shwartz}, Shai and Tewari, Ambuj},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(3).pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Pages = {1865−-1892},
	Title = {{Stochastic methods for l1-regularized loss minimization}},
	Volume = {12},
	Year = {2011}}

@article{DuanPettie2014,
	Author = {Duan, Ran and Pettie, Seth},
	Doi = {10.1145/2529989},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/3492dea6a70b4a1339999fc8ae8e26be784d1cb1.pdf:pdf},
	Issn = {00045411},
	Journal = {Journal of the ACM},
	Mendeley-Groups = {Algorithms/Maxflow},
	Month = jan,
	Number = {1},
	Pages = {1--23},
	Title = {{Linear-Time Approximation for Maximum Weight Matching}},
	Volume = {61},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2529989}}

@inproceedings{Zouzias2012,
	Acmid = {2359454},
	Address = {Berlin, Heidelberg},
	Author = {Zouzias, Anastasios},
	Booktitle = {Proceedings of the 39th International Colloquium Conference on Automata, Languages, and Programming - Volume Part I},
	Doi = {10.1007/978-3-642-31594-7_71},
	Isbn = {978-3-642-31593-0},
	Location = {Warwick, UK},
	Numpages = {13},
	Pages = {846--858},
	Publisher = {Springer-Verlag},
	Series = {ICALP'12},
	Title = {A Matrix Hyperbolic Cosine Algorithm and Applications},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-31594-7_71}}

@incollection{Hazan2012-survey,
	Author = {Hazan, Elad},
	Booktitle = {Optimization for machine learning},
	Chapter = {10},
	Editors = {Suvrit Sra, Sebastian Nowozin and Stephen J. Wright},
	Pages = {287--304},
	Publisher = {MIT press},
	Title = {The Convex Optimization Approach to Regret Minimization},
	Year = {2012}}

@inproceedings{CharikarLLM10,
	Author = {Moses Charikar and Tom Leighton and Shi Li and Ankur Moitra},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/conf/focs/CharikarLLM10},
	Booktitle = {51th Annual {IEEE} Symposium on Foundations of Computer Science, {FOCS} 2010, October 23-26, 2010, Las Vegas, Nevada, {USA}},
	Doi = {10.1109/FOCS.2010.32},
	Pages = {265--274},
	Timestamp = {Mon, 03 Nov 2014 22:22:11 +0100},
	Title = {Vertex Sparsifiers and Abstract Rounding Algorithms},
	Url = {http://doi.ieeecomputersociety.org/10.1109/FOCS.2010.32},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.ieeecomputersociety.org/10.1109/FOCS.2010.32},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/FOCS.2010.32}}

@inproceedings{PengS14,
	Author = {Richard Peng and Daniel A. Spielman},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/conf/stoc/PengS14},
	Booktitle = {Symposium on Theory of Computing, {STOC} 2014, New York, NY, USA, May 31 - June 03, 2014},
	Doi = {10.1145/2591796.2591832},
	Pages = {333--342},
	Timestamp = {Mon, 03 Nov 2014 22:25:46 +0100},
	Title = {An efficient parallel solver for {SDD} linear systems},
	Url = {http://doi.acm.org/10.1145/2591796.2591832},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2591796.2591832},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2591796.2591832}}

@book{Bhatia1997,
	Address = {New York, NY},
	Author = {Bhatia, Rajendra},
	Doi = {10.1007/978-1-4612-0653-8},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatia - 1997 - Matrix Analysis.pdf:pdf},
	Isbn = {978-1-4612-6857-4},
	Mendeley-Groups = {Books/Algebra},
	Publisher = {Springer New York},
	Series = {Graduate Texts in Mathematics},
	Title = {{Matrix Analysis}},
	Volume = {169},
	Year = {1997},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-1-4612-0653-8}}

@article{Naor2012,
	Author = {Naor, Assaf},
	Journal = {Ast{\'e}risque},
	Publisher = {Soci{\'e}t{\'e} math{\'e}matique de France},
	Title = {SPARSE QUADRATIC FORMS AND THEIR GEOMETRIC APPLICATIONS [after {B}atson, {S}pielman and {S}rivastava]},
	Year = {2012}}

@article{JainJiUpadhyayWatrous2009,
	Author = {Jain, Rahul and Ji, Zhengfeng and Upadhyay, Sarvagya and Watrous, John},
	Journal = {Journal of the ACM (JACM)},
	Number = {6},
	Pages = {30},
	Publisher = {ACM},
	Title = {{QIP = PSPACE}},
	Volume = {58},
	Year = {2011}}

@article{HazanAK2007,
	Author = {Hazan, Elad and Agarwal, Amit and Kale, Satyen},
	Doi = {10.1007/s10994-007-5016-8},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Agarwal, Kale - 2007 - Logarithmic regret algorithms for online convex optimization.pdf:pdf},
	Issn = {0885-6125},
	Journal = {Machine Learning},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Month = aug,
	Number = {2-3},
	Pages = {169--192},
	Title = {{Logarithmic regret algorithms for online convex optimization}},
	Volume = {69},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10994-007-5016-8}}

@inproceedings{Saha2011,
	Abstract = {Given \$n\$ points in a \$d\$ dimensional Euclidean space, the Minimum Enclosing Ball (MEB) problem is to find the ball with the smallest radius which contains all \$n\$ points. We give a \$O(nd\backslash Qcal/\backslash sqrt\{\backslash epsilon\})\$ approximation algorithm for producing an enclosing ball whose radius is at most \$\backslash epsilon\$ away from the optimum (where \$\backslash Qcal\$ is an upper bound on the norm of the points). This improves existing results using $\backslash$emph\{coresets\}, which yield a \$O(nd/\backslash epsilon)\$ greedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a related problem wherein a convex polytope of a fixed shape is given and the aim is to find the smallest magnification of the polytope which encloses the given points. For this problem we present a \$O(mnd\backslash Qcal/\backslash epsilon)\$ approximation algorithm, where \$m\$ is the number of faces of the polytope. Our algorithms borrow heavily from convex duality and recently developed techniques in non-smooth optimization, and are in contrast with existing methods which rely on geometric arguments. In particular, we specialize the excessive gap framework of $\backslash$citet\{Nesterov05a\} to obtain our results.},
	Archiveprefix = {arXiv},
	Arxivid = {0909.1062},
	Author = {Saha, Ankan and Vishwanathan, S. V. N. and Zhang, Xinhua},
	Booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '11},
	Eprint = {0909.1062},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Saha, Vishwanathan, Zhang - 2011 - New Approximation Algorithms for Minimum Enclosing Convex Shapes.pdf:pdf},
	Mendeley-Groups = {Algorithms/Computational Geometry},
	Month = sep,
	Pages = {1146--1160},
	Title = {{New Approximation Algorithms for Minimum Enclosing Convex Shapes}},
	Year = {2011}}

@inproceedings{Xie2006,
	Author = {Xie, Yulai and Snoeyink, Jack and Xu, Jinhui},
	Booktitle = {Proceedings of the 22nd annual symposium on computational geometry - SCG '06},
	Doi = {10.1145/1137856.1137861},
	Isbn = {1595933409},
	Mendeley-Groups = {Algorithms/Computational Geometry},
	Title = {{Efficient algorithm for approximating maximum inscribed sphere in high dimensional polytope}},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1137856.1137861}}

@article{nesterov2008rounding,
	Author = {Nesterov, Yu},
	Journal = {Optimisation Methods and Software},
	Number = {1},
	Pages = {109--128},
	Publisher = {Taylor \& Francis},
	Title = {Rounding of convex sets and efficient gradient methods for linear programming problems},
	Volume = {23},
	Year = {2008}}

@article{Kumar2003,
	Author = {Kumar, Piyush and Mitchell, Joseph S. B. and Yildirim, E. Alper},
	Doi = {10.1145/996546.996548},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kumar, Mitchell, Yildirim - 2003 - Approximate minimum enclosing balls in high dimensions using core-sets.pdf:pdf},
	Issn = {10846654},
	Journal = {Journal of Experimental Algorithmics},
	Mendeley-Groups = {Algorithms/Computational Geometry},
	Month = jan,
	Pages = {1--29},
	Title = {{Approximate minimum enclosing balls in high dimensions using core-sets}},
	Volume = {8},
	Year = {2003},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/996546.996548}}

@inproceedings{Chudak2005,
	Author = {Chudak, Fabi\'{a}n A. and Eleut\'{e}rio, V\^{a}nia},
	Booktitle = {Proceedings of the 11th International IPCO Conference on Integer Programming and Combinatorial Optimization},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Chudak, Eleut\'{e}rio - 2005 - Improved Approximation Schemes for Linear Programming Relaxations of Combinatorial Optimization Problems.pdf:pdf},
	Mendeley-Groups = {Optimization/Multiplicative Weight/LP},
	Pages = {81--96},
	Title = {{Improved Approximation Schemes for Linear Programming Relaxations of Combinatorial Optimization Problems}},
	Year = {2005}}

@article{ClarksonHW2012,
	Author = {Clarkson, Kenneth L. and Hazan, Elad and Woodruff, David P.},
	Doi = {10.1145/2371656.2371658},
	File = {:D$\backslash$:/Mendeley Desktop/Clarkson, Hazan, Woodruff - 2012 - Sublinear optimization for machine learning.pdf:pdf},
	Issn = {00045411},
	Journal = {Journal of the ACM},
	Mendeley-Groups = {Algorithms/Computational Geometry},
	Month = oct,
	Number = {5},
	Pages = {23:1--23:49},
	Title = {{Sublinear optimization for machine learning}},
	Volume = {59},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2371656.2371658}}

@inproceedings{Badoiu2002,
	Address = {New York, New York, USA},
	Author = {{B{\u{a}}doiu}, Mihai and {Har-Peled}, Sariel and Indyk, Piotr},
	Booktitle = {Proceedings of the thiry-fourth annual ACM symposium on Theory of computing - STOC '02},
	Doi = {10.1145/509907.509947},
	Isbn = {1581134959},
	Mendeley-Groups = {Algorithms/Computational Geometry},
	Pages = {250},
	Publisher = {ACM Press},
	Title = {{Approximate clustering via core-sets}},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/509907.509947}}

@article{sylvester1857question,
	Author = {Sylvester, James Joseph},
	Journal = {Quarterly Journal of Pure and Applied Mathematics},
	Title = {A question in the geometry of situation},
	Volume = {1},
	Year = {1857}}

@article{elzinga1975central,
	Author = {Elzinga, Jack and Moore, Thomas G.},
	Journal = {Mathematical Programming},
	Number = {1},
	Pages = {134--145},
	Publisher = {Springer},
	Title = {A central cutting plane algorithm for the convex programming problem},
	Volume = {8},
	Year = {1975}}

@article{agarwal2005geometric,
	Author = {Agarwal, Pankaj K. and {Har-Peled}, Sariel and Varadarajan, Kasturi R.},
	Journal = {Combinatorial and computational geometry},
	Pages = {1--30},
	Publisher = {Cambridge University Press New York},
	Title = {Geometric approximation via coresets},
	Volume = {52},
	Year = {2005}}

@article{anstreicher2002improved,
	Author = {Anstreicher, Kurt M.},
	Journal = {SIAM Journal on Optimization},
	Number = {2},
	Pages = {309--320},
	Publisher = {SIAM},
	Title = {Improved complexity for maximum volume inscribed ellipsoids},
	Volume = {13},
	Year = {2002}}

@article{khachiyan1993complexity,
	Author = {Khachiyan, Leonid G and Todd, Michael J},
	Journal = {Mathematical Programming},
	Number = {1},
	Pages = {137--159},
	Publisher = {Springer},
	Title = {On the complexity of approximating the maximal inscribed ellipsoid for a polytope},
	Volume = {61},
	Year = {1993}}

@book{nesterov1994interior,
	Author = {Nesterov, Yurii and Nemirovskii, Arkadii and Ye, Yinyu},
	Publisher = {SIAM},
	Title = {Interior-point polynomial algorithms in convex programming},
	Volume = {13},
	Year = {1994}}

@techreport{nemirovski1997,
	Author = {Nemirovskii, Arkadii},
	Institution = {Optimization Laboratory Faculty of Industrial Engineering and Management, The Technion - Israel Institute of Technology},
	Month = jun,
	Number = {\# 3/97},
	Title = {On self-concordant convex-concave functions},
	Year = {1997}}

@article{khachiyan1996rounding,
	Author = {Khachiyan, Leonid G.},
	Journal = {Mathematics of Operations Research},
	Number = {2},
	Pages = {307--320},
	Publisher = {INFORMS},
	Title = {Rounding of polytopes in the real number model of computation},
	Volume = {21},
	Year = {1996}}

@article{clarkson2010coresets,
	Author = {Clarkson, Kenneth L},
	Journal = {ACM Transactions on Algorithms (TALG)},
	Number = {4},
	Pages = {63},
	Publisher = {ACM},
	Title = {Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm},
	Volume = {6},
	Year = {2010}}

@inproceedings{gartner2009coresets,
	Author = {G{\"a}rtner, Bernd and Jaggi, Martin},
	Booktitle = {Proceedings of the 25th annual symposium on computational geometry},
	Organization = {ACM},
	Pages = {33--42},
	Title = {Coresets for polytope distance},
	Year = {2009}}

@inproceedings{har2007maximum,
	Author = {{Har-Peled}, Sariel and Roth, Dan and Zimak, Dav},
	Booktitle = {Proceedings of the 20th international joint conference on Artifical intelligence},
	Organization = {Morgan Kaufmann Publishers Inc.},
	Pages = {836--841},
	Title = {Maximum margin coresets for active and noise tolerant learning},
	Year = {2007}}

@book{welzl1991smallest,
	Author = {Welzl, Emo},
	Publisher = {Springer},
	Title = {Smallest enclosing disks (balls and ellipsoids)},
	Year = {1991}}

@article{yildirim2008two,
	Author = {Yildirim, E. Alper},
	Journal = {SIAM Journal on Optimization},
	Number = {3},
	Pages = {1368--1391},
	Publisher = {SIAM},
	Title = {Two algorithms for the minimum enclosing ball problem},
	Volume = {19},
	Year = {2008}}

@article{Nesterov2005excessive,
	Annote = {YinTat mentioned that this paper may have combined the primal/dual descent steps of Nesterov into (either one or two, I forgot) Prox steps.},
	Author = {Nesterov, Yurii},
	Doi = {10.1137/S1052623403422285},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nesterov - 2005 - Excessive Gap Technique in Nonsmooth Convex Minimization.pdf:pdf},
	Issn = {1052-6234},
	Journal = {SIAM Journal on Optimization},
	Keywords = {black-box oracle,complexity theory,convex optimization,non-smooth optimization,optimal methods,structural},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Month = jan,
	Number = {1},
	Pages = {235--249},
	Title = {{Excessive Gap Technique in Nonsmooth Convex Minimization}},
	Volume = {16},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S1052623403422285}}

@article{buadoiu2008optimal,
	Author = {B{\u{a}}doiu, Mihai and Clarkson, Kenneth L},
	Journal = {Computational Geometry},
	Number = {1},
	Pages = {14--22},
	Publisher = {Elsevier},
	Title = {Optimal core-sets for balls},
	Volume = {40},
	Year = {2008}}

@article{sion1958general,
	Author = {Sion, Maurice},
	Journal = {Pacific Journal of Mathematics},
	Number = {1},
	Pages = {171--176},
	Publisher = {Pacific Journal of Mathematics},
	Title = {On general minimax theorems.},
	Volume = {8},
	Year = {1958}}

@article{lee2011chebyshev,
	Author = {Lee, Chungmok and Park, Sungsoo},
	Journal = {Discrete Applied Mathematics},
	Number = {18},
	Pages = {2251--2265},
	Publisher = {Elsevier},
	Title = {Chebyshev center based column generation},
	Volume = {159},
	Year = {2011}}

@inproceedings{su2014differential,
	Author = {Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2510--2518},
	Title = {A Differential Equation for Modeling Nesterov's Accelerated Gradient Method: Theory and Insights},
	Year = {2014}}

@article{murty2012m,
	Author = {Murty, Katta G.},
	Journal = {Algorithmic Operations Research},
	Number = {1},
	Pages = {30--40},
	Title = {$O(m)$ Bound on Number of Iterations in Sphere Methods for LP},
	Volume = {7},
	Year = {2012}}

@article{zhou2005efficient,
	Author = {Zhou, Guanglu and Tohemail, Kim-Chuan and Sun, Jie},
	Journal = {Computational Optimization and Applications},
	Number = {2},
	Pages = {147--160},
	Publisher = {Springer},
	Title = {Efficient algorithms for the smallest enclosing ball problem},
	Volume = {30},
	Year = {2005}}

@inproceedings{HazanKS2012,
	Abstract = {In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (beta,tau)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of O*(sqrt(beta tau T)) for all problems in which the comparison class is composed of (beta,tau)-decomposable matrices. By analyzing the decomposability of cut matrices, triangular matrices, and low trace-norm matrices, we derive near optimal regret bounds for online max-cut, online gambling, and online collaborative filtering. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1204.0136v1},
	Author = {Hazan, Elad and Kale, Satyen and {Shalev-Shwartz}, Shai},
	Booktitle = {Proceedings of the 25th Annual Conference on Learning Theory - COLT '12},
	Eprint = {arXiv:1204.0136v1},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Kale, Shalev-Shwartz - 2012 - Near-optimal algorithms for online matrix prediction.pdf:pdf},
	Issn = {15337928},
	Mendeley-Groups = {Optimization/Mirror Descent/Mirror Descent for NP-hard Problems},
	Pages = {38.1----38.13},
	Title = {{Near-optimal algorithms for online matrix prediction}},
	Url = {http://arxiv.org/abs/1204.0136},
	Year = {2012},
	Bdsk-Url-1 = {http://arxiv.org/abs/1204.0136}}

@article{Grigoriadis1995,
	Abstract = {This paper presents a parallel randomizedalgorithm which computes a pair of $\epsilon$-optimal strategies for a given (m,n)-matrixgameA = [aij] ? [?1, 1] in O($\epsilon$?2log2(n+m)) expected time on an (n+m)/log(n+m)-processor EREW PRAM. For any fixed accuracy ? > 0, the expected sequential running time of the suggested algorithm is O((n + m)log(n + m)), which is sublinear in mn, the number of input elements of A. On the other hand, simple arguments are given to show that for , any deterministic algorithm for computing a pair of $\epsilon$-optimal strategies of an (m, n)-matrixgameA with $\pm$ 1 elements examines $\Omega$(mn) of its elements. In particular, for m = n the randomizedalgorithm achieves an almost quadratic expected speedup relative to any deterministic method.},
	Author = {Grigoriadis, Michael D. and Khachiyan, Leonid G.},
	Doi = {10.1016/0167-6377(95)00032-0},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grigoriadis, Khachiyan - 1995 - A sublinear-time randomized approximation algorithm for matrix games.pdf:pdf},
	Issn = {01676377},
	Journal = {Operations Research Letters},
	Keywords = {approximation algorithms,complexity,linear programming,matrix games,parallel algorithms,randomized},
	Mendeley-Groups = {Optimization/Multiplicative Weight/LP},
	Pages = {53--58},
	Title = {{A sublinear-time randomized approximation algorithm for matrix games}},
	Volume = {18},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/0167-6377(95)00032-0}}

@article{XiaoZhang2014-ProximalSVRG,
	Abstract = {We consider the problem of minimizing the sum of two convex functions: one is the average of a large number of smooth component functions, and the other is a general convex function that admits a simple proximal mapping. We assume the whole objective function is strongly convex. Such problems often arise in machine learning, known as regularized empirical risk minimization. We propose and analyze a new proximal stochastic gradient method, which uses a multi-stage scheme to progressively reduce the variance of the stochastic gradient. While each iteration of this algorithm has similar cost as the classical stochastic gradient method (or incremental gradient method), we show that the expected objective value converges to the optimum at a geometric rate. The overall complexity of this method is much lower than both the proximal full gradient method and the standard proximal stochastic gradient method. 1},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1403.4699v1},
	Author = {Xiao, Lin and Zhang, Tong},
	Doi = {10.1137/140961791},
	Eprint = {arXiv:1403.4699v1},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao, Zhang - 2014 - A Proximal Stochastic Gradient Method with Progressive Variance Reduction(2).pdf:pdf},
	Issn = {1052-6234},
	Journal = {SIAM Journal on Optimization},
	Mendeley-Groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
	Number = {4},
	Pages = {2057----2075},
	Title = {{A Proximal Stochastic Gradient Method with Progressive Variance Reduction}},
	Volume = {24},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/140961791}}

@inproceedings{JohnsonZhang2013-SVRG,
	Author = {Johnson, Rie and Zhang, Tong},
	Booktitle = {Advances in Neural Information Processing Systems},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Johnson, Zhang - 2013 - Accelerating stochastic gradient descent using predictive variance reduction.pdf:pdf},
	Mendeley-Groups = {Optimization/Variance Reduction,Optimization/[with Yuan Yang]},
	Pages = {315--323},
	Series = {NIPS 2013},
	Title = {{Accelerating stochastic gradient descent using predictive variance reduction}},
	Url = {http://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction},
	Year = {2013},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction}}

@inproceedings{Defazio2014-SAGA,
	Abstract = {In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1407.0202v2},
	Author = {Defazio, Aaron and Bach, Francis and {Lacoste-Julien}, Simon},
	Booktitle = {Advances in Neural Information Processing Systems},
	Eprint = {arXiv:1407.0202v2},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Defazio, Bach, Lacoste-Julien - 2014 - SAGA A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.pdf:pdf},
	Mendeley-Groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
	Series = {NIPS 2014},
	Title = {{SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives}},
	Url = {http://arxiv.org/abs/1407.0202},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1407.0202}}

@inproceedings{Defazio2014-Finito,
	Abstract = {Recent advances in optimization theory have shown that smooth strongly convex finite sums can be minimized faster than by treating them as a black box ''batch'' problem. In this work we introduce a new method in this class with a theoretical convergence rate four times faster than existing methods, for sums with sufficiently many terms. This method is also amendable to a sampling without replacement scheme that in practice gives further speed-ups. We give empirical results showing state of the art performance. 1},
	Archiveprefix = {arXiv},
	Arxivid = {1407.2710},
	Author = {Defazio, Aaron J. and Caetano, Tib\'{e}rio S. and Domke, Justin},
	Booktitle = {Proceedings of the 31st International Conference on Machine Learning},
	Eprint = {1407.2710},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Defazio, Caetano, Domke - 2014 - Finito A Faster, Permutable Incremental Gradient Method for Big Data Problems.pdf:pdf},
	Mendeley-Groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
	Series = {ICML 2014},
	Title = {{Finito: A Faster, Permutable Incremental Gradient Method for Big Data Problems}},
	Url = {http://jmlr.org/proceedings/papers/v32/defazio14.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://jmlr.org/proceedings/papers/v32/defazio14.pdf}}

@article{Mairal2015-MISO,
	Author = {Mairal, Julien},
	Doi = {10.1137/140957639},
	File = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Mairal - 2015 - Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning.pdf:pdf},
	Issn = {1052-6234},
	Journal = {SIAM Journal on Optimization},
	Keywords = {1,10,1137,140957639,90c06,90c25,90c26,ams subject classifications,convex optimization,doi,introduction,majorization-minimization,minimizing upper bounds of,nonconvex optimization,the,the principle of successively},
	Mendeley-Groups = {Optimization/Variance Reduction},
	Month = apr,
	Note = {Preliminary version appeared in ICML 2013},
	Number = {2},
	Pages = {829--855},
	Title = {{Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning}},
	Url = {http://epubs.siam.org/doi/10.1137/140957639},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {http://epubs.siam.org/doi/10.1137/140957639},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/140957639}}

@article{Schmidt2013-SAG,
	Abstract = {We propose the stochastic average gradient (SAG) method for optimizing the sum of a finite number of smooth convex functions. Like stochastic gradient (SG) methods, the SAG method's iteration cost is independent of the number of terms in the sum. However, by incorporating a memory of previous gradient values the SAG method achieves a faster convergence rate than black-box SG methods. The convergence rate is improved from O(1/k\^{}\{1/2\}) to O(1/k) in general, and when the sum is strongly-convex the convergence rate is improved from the sub-linear O(1/k) to a linear convergence rate of the form O(p\^{}k) for p < 1. Further, in many cases the convergence rate of the new method is also faster than black-box deterministic gradient methods, in terms of the number of gradient evaluations. Numerical experiments indicate that the new algorithm often dramatically outperforms existing SG and deterministic gradient methods, and that the performance may be further improved through the use of non-uniform sampling strategies.},
	Archiveprefix = {arXiv},
	Arxivid = {1309.2388},
	Author = {Schmidt, Mark and {Le Roux}, Nicolas and Bach, Francis},
	Eprint = {1309.2388},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/6bb9f6695c64ca57938706579bcdff9c8712f8e9.pdf:pdf},
	Journal = {arXiv preprint arXiv:1309.2388},
	Mendeley-Groups = {Optimization/Variance Reduction},
	Note = {Preliminary version appeared in NIPS 2012},
	Pages = {1--45},
	Title = {{Minimizing finite sums with the stochastic average gradient}},
	Url = {http://arxiv.org/abs/1309.2388},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1309.2388}}

@inproceedings{zhang2004solving,
	Author = {Zhang, Tong},
	Booktitle = {Proceedings of the 21st International Conference on Machine Learning},
	Series = {ICML 2004},
	Title = {Solving large scale linear prediction problems using stochastic gradient descent algorithms},
	Year = {2004}}

@misc{Bottou-SGD,
	Author = {L\'{e}on Bottou},
	Howpublished = {\url{http://leon.bottou.org/projects/sgd}},
	Title = {Stochastic Gradient Descent},
	Year = 2007}

@article{Shalev-Shwartz2013-SDCA,
	Author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shalev-Shwartz, Zhang - 2013 - Stochastic dual coordinate ascent methods for regularized loss minimization.pdf:pdf},
	Journal = {Journal of Machine Learning Research},
	Keywords = {computational complexity,ized loss minimization,logistic regression,optimization,regular-,ridge regression,stochastic dual coordinate ascent,support vector machines},
	Mendeley-Groups = {Optimization/Stochastic Online Optimization},
	Pages = {567--599},
	Title = {{Stochastic dual coordinate ascent methods for regularized loss minimization}},
	Url = {http://arxiv.org/abs/1209.1873},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1209.1873}}

@inproceedings{Ng2004-L1LR,
	Author = {Ng, Andrew Y.},
	Booktitle = {Proceedings of the 21st International Conference on Machine Learning},
	Organization = {ACM},
	Pages = {78},
	Series = {ICML 2004},
	Title = {Feature selection, {L1 vs. L2} regularization, and rotational invariance},
	Year = {2004}}

@article{Tibshirani1996-Lasso,
	Author = {Tibshirani, Robert},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Pages = {267--288},
	Publisher = {JSTOR},
	Title = {Regression shrinkage and selection via the lasso},
	Year = {1996}}

@inproceedings{LLX2014-ProxSDCA-APCG,
	Annote = {A short version has appeared in NIPS 2014 with its first 3 sections.},
	Archiveprefix = {arXiv},
	Arxivid = {1407.1296},
	Author = {Lin, Qihang and Lu, Zhaosong and Xiao, Lin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Eprint = {1407.1296},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Lu, Xiao - 2014 - An Accelerated Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimizat(2).pdf:pdf},
	Mendeley-Groups = {Optimization/[with Yuan Yang],Optimization/Stochastic Online Optimization,Optimization/Coordinate Descent},
	Pages = {3059--3067},
	Series = {NIPS 2014},
	Title = {{An Accelerated Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimization}},
	Url = {http://arxiv.org/abs/1407.1296 http://papers.nips.cc/paper/5356-an-accelerated-proximal-coordinate-gradient-method.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1407.1296%20http://papers.nips.cc/paper/5356-an-accelerated-proximal-coordinate-gradient-method.pdf}}

@article{LuXiao2013,
	Author = {Lu, Zhaosong and Xiao, Lin},
	Journal = {Mathematical Programming},
	Pages = {1--28},
	Publisher = {Springer},
	Title = {On the complexity analysis of randomized block-coordinate descent methods},
	Year = {2013}}

@inproceedings{ZhangXiao2015-SPDC,
	Abstract = {We consider a generic convex optimization problem associated with regularized empirical risk minimization of linear predictors. The problem structure allows us to reformulate it as a convex-concave saddle point problem. We propose a stochastic primal-dual coordinate (SPDC) method, which alternates between maximizing over a randomly chosen dual variable and minimizing over the primal variable. An extrapolation step on the primal variable is performed to obtain accelerated convergence rate. We also develop a mini-batch version of the SPDC method which facilitates parallel computing, and an extension with weighted sampling probabilities on the dual variables, which has a better complexity than uniform sampling on unnormalized data. Both theoretically and empirically, we show that the SPDC method has comparable or better performance than several state-of-the-art optimization methods.},
	Archiveprefix = {arXiv},
	Arxivid = {1409.3257},
	Author = {Zhang, Yuchen and Xiao, Lin},
	Booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
	Eprint = {1409.3257},
	File = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/1ca7470da54bcc99493d1dac5f702ca0b9ea4d23.pdf:pdf},
	Mendeley-Groups = {Optimization/Saddle-Point,Optimization/[with Yuan Yang]},
	Series = {ICML 2015},
	Title = {{Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization}},
	Url = {http://arxiv.org/abs/1409.3257},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.3257}}

@article{Nesterov2012,
	Abstract = {In this paper we propose new methods for solving huge-scale optimization problems. For problems of this size, even the simplest full-dimensional vector operations are very expensive. Hence, we propose to apply an optimization technique based on random partial update of decision variables. For these methods, we prove the global estimates for the rate of convergence. Surprisingly, for certain classes of objective functions, our results are better than the standard worst-case bounds for deterministic algorithms. We present constrained and unconstrained versions of the method and its accelerated variant. Our numerical test confirms a high efficiency of this technique on problems of very big size. Read More: http://epubs.siam.org/doi/abs/10.1137/100802001},
	Author = {Nesterov, Yurii},
	Doi = {10.1137/100802001},
	File = {:D$\backslash$:/Mendeley Desktop/Nesterov - 2012 - Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems.pdf:pdf},
	Issn = {1052-6234},
	Journal = {SIAM Journal on Optimization},
	Keywords = {Google problem,convex optimization,coordinate relaxation,fast gradient schemes,worst-case efficiency estimates},
	Mendeley-Groups = {Optimization/Coordinate Descent},
	Month = {jan},
	Number = {2},
	Pages = {341--362},
	Title = {{Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems}},
	Url = {http://130.104.5.100/cps/ucl/doc/core/documents/coredp2010{\_}2web.pdf http://epubs.siam.org/doi/abs/10.1137/100802001},
	Volume = {22},
	Year = {2012},
	Bdsk-Url-1 = {http://130.104.5.100/cps/ucl/doc/core/documents/coredp2010%7B%5C_%7D2web.pdf%20http://epubs.siam.org/doi/abs/10.1137/100802001},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/100802001}}

@inproceedings{LeeSidford2013,
	Author = {Lee, Yin Tat and Sidford, Aaron},
	Booktitle = {Foundations of Computer Science (FOCS), 2013 IEEE 54th Annual Symposium on},
	Organization = {IEEE},
	Pages = {147--156},
	Title = {Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems},
	Year = {2013}}

@article{LeventhalLewis2010,
	Author = {Leventhal, Dennis and Lewis, Adrian S},
	Journal = {Mathematics of Operations Research},
	Number = {3},
	Pages = {641--654},
	Publisher = {INFORMS},
	Title = {Randomized methods for linear constraints: convergence rates and conditioning},
	Volume = {35},
	Year = {2010}}

@article{RichtarikTakac2014,
	Author = {Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
	Journal = {Mathematical Programming},
	Number = {1-2},
	Pages = {1--38},
	Publisher = {Springer},
	Title = {Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
	Volume = {144},
	Year = {2014}}

@inproceedings{BradleyKBG2011,
	Author = {Bradley, Joseph K. and Kyrola, Aapo and Bickson, Danny and Guestrin, Carlos},
	Booktitle = {Proceedings of the 28th International Conference on Machine Learning},
	Series = {ICML' 11},
	Title = {Parallel coordinate descent for l1-regularized loss minimization},
	Year = {2011}}

@article{RichtarikTakac2012parallel,
	Author = {Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
	Journal = {Mathematical Programming},
	Pages = {1--52},
	Publisher = {Springer},
	Title = {Parallel coordinate descent methods for big data optimization},
	Year = {2012}}

@inproceedings{TakacBRS2013,
	Author = {Takac, Martin and Bijral, Avleen and Richtarik, Peter and Srebro, Nati},
	Booktitle = {Proceedings of The 30th International Conference on Machine Learning},
	Pages = {1022--1030},
	Title = {Mini-Batch Primal and Dual Methods for SVMs},
	Year = {2013}}

@article{NecoaraClipici2013,
	Author = {Necoara, Ion and Clipici, Dragos},
	Journal = {Journal of Process Control},
	Number = {3},
	Pages = {243--253},
	Publisher = {Elsevier},
	Title = {Efficient parallel coordinate descent algorithm for convex optimization problems with separable constraints: application to distributed MPC},
	Volume = {23},
	Year = {2013}}

@article{FercoqRichtarik2013smooth,
	Author = {{Fercoq}, Olivier and {Richt{\'a}rik}, Peter},
	Journal = {ArXiv e-prints},
	Month = sep,
	Title = {Smooth minimization of nonsmooth functions with parallel coordinate descent methods},
	Volume = {abs/1309.5885},
	Year = 2013}

@article{RichtarikTakac2013distributed,
	Author = {Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
	Journal = {arXiv preprint arXiv:1310.2059},
	Title = {Distributed coordinate descent method for learning with big data},
	Year = {2013}}

@inproceedings{LiuWRBS2014asynchronous,
	Author = {Liu, Ji and Wright, Steve and Re, Christopher and Bittorf, Victor and Sridhar, Srikrishna},
	Booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
	Pages = {469--477},
	Title = {An Asynchronous Parallel Stochastic Coordinate Descent Algorithm},
	Year = {2014}}

@inproceedings{LinMH2015-Catalyst,
	Archiveprefix = {arXiv},
	Arxivid = {1506.02186},
	Author = {Lin, Hongzhou and Mairal, Julien and Harchaoui, Zaid},
	Booktitle = {NIPS},
	Eprint = {1506.02186},
	File = {:D$\backslash$:/Mendeley Desktop/Lin, Mairal, Harchaoui - 2015 - A Universal Catalyst for First-Order Optimization.pdf:pdf},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Title = {{A Universal Catalyst for First-Order Optimization}},
	Url = {http://arxiv.org/pdf/1506.02186v1.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1506.02186v1.pdf}}

@inproceedings{FrostigGKS2015-Catalyst,
	Abstract = {We develop a family of accelerated stochastic algorithms that minimize sums of convex functions. Our algorithms improve upon the fastest running time for empirical risk minimization (ERM), and in particular linear least-squares regression, across a wide range of problem settings. To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion. Empirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem.},
	Archiveprefix = {arXiv},
	Arxivid = {1506.07512},
	Author = {Frostig, Roy and Ge, Rong and Kakade, Sham M. and Sidford, Aaron},
	Booktitle = {ICML},
	Eprint = {1506.07512},
	File = {:D$\backslash$:/Mendeley Desktop/Frostig et al. - 2015 - Un-regularizing approximate proximal point and faster stochastic algorithms for empirical risk minimization.pdf:pdf},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Pages = {1--28},
	Title = {{Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization}},
	Url = {http://arxiv.org/abs/1506.07512},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.07512}}

@article{ChambollePock2011,
	Abstract = {In this paper we study a first-order primal-dual algorithm for non-smooth convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions for the complete class of problems. We further show accelerations of the proposed algorithm to yield improved rates on problems with some degree of smoothness. In particular we show that we can achieve O(1/N 2) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O($\omega$ N ) for some $\omega$∈(0,1), on smooth problems. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and multi-label image segmentation.},
	Annote = {Gives the full-gradient based accelerated algorithm for the saddle point problem.},
	Author = {Chambolle, Antonin and Pock, Thomas},
	Doi = {10.1007/s10851-010-0251-1},
	File = {:D$\backslash$:/Mendeley Desktop/Chambolle, Pock - 2011 - A first-order primal-dual algorithm for convex problems with applications to imaging.pdf:pdf},
	Isbn = {1085101002},
	Issn = {09249907},
	Journal = {Journal of Mathematical Imaging and Vision},
	Keywords = {Convex optimization,Dual approaches,Image,Inverse problems,Reconstruction,Total variation},
	Mendeley-Groups = {Optimization/Gradient Descent Theory},
	Number = {1},
	Pages = {120--145},
	Title = {{A first-order primal-dual algorithm for convex problems with applications to imaging}},
	Volume = {40},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10851-010-0251-1}}

@misc{LibSVMdata,
	Author = {Fan, Rong-En and Lin, Chih-Jen},
	Note = {Accessed: 2015-06},
	Title = {{LIBSVM Data: Classification, Regression and Multi-label}},
	Url = {http://www. csie. ntu. edu. tw/cjlin/libsvmtools/datasets},
	Year = {2011},
	Bdsk-Url-1 = {http://www.%20csie.%20ntu.%20edu.%20tw/cjlin/libsvmtools/datasets}}

@article{AO-survey-nesterov,
	Author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Journal = {ArXiv e-prints},
	Month = jul,
	Title = {Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent},
	Volume = {abs/1407.1537},
	Year = {2014}}

@inproceedings{AO-lp-parallel,
	Author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
	Booktitle = {Proceedings of the 26th ACM-SIAM Symposium on Discrete Algorithms},
	Series = {SODA~'15},
	Title = {Using Optimization to Break the Epsilon Barrier: A Faster and Simpler Width-Independent Algorithm for Solving Positive Linear Programs in Parallel},
	Year = {2015}}

@article{AO-lp-parallel-arxiv,
	Author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Journal = {ArXiv e-prints},
	Month = jul,
	Title = {Using Optimization to Break the Epsilon Barrier: A Faster and Simpler Width-Independent Algorithm for Solving Positive Linear Programs in Parallel},
	Volume = {abs/1407.1925},
	Year = {2014}}

@inproceedings{AO-lp-coordinate,
	Author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
	Booktitle = {Proceedings of the 47th Annual ACM Symposium on Theory of Computing},
	Series = {STOC~'15},
	Title = {{Nearly-Linear Time Positive LP Solver with Faster Convergence Rate}},
	Year = {2015}}

@inproceedings{ALO-bss,
	Author = {{Allen-Zhu}, Zeyuan and Liao, Zhenyu and Orecchia, Lorenzo},
	Booktitle = {Proceedings of the 47th Annual ACM Symposium on Theory of Computing},
	Series = {STOC~'15},
	Title = {{Spectral Sparsification and Regret Minimization Beyond Multiplicative Updates}},
	Year = {2015}}

@inproceedings{NSLIFK-gauss-southwell,
	Author = {Nutini, Julie and Schmidt, Mark and Laradji, Issam and Friedlander, Michael and Koepke, Hoyt},
	Booktitle = {Proceedings of the 32nd International Conference on Machine Learning (ICML-15)},
	Pages = {1632-1641},
	Title = {Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection},
	Year = {2015}}

@inproceedings{NWS-Kaczmarz-algorithm,
	Author = {Needell, Deanna and Ward, Rachel and Srebro, Nati},
	Booktitle = {Advances in Neural Information Processing Systems 27},
	Pages = {1017--1025},
	Title = {Stochastic Gradient Descent, Weighted Sampling, and the Randomized Kaczmarz algorithm},
	Year = {2014}}

@article{QRZ-arbitrary-sampling,
	Author = {Zheng Qu and Peter Richt{\'{a}}rik and Tong Zhang},
	Journal = {CoRR},
	Title = {Randomized Dual Coordinate Ascent with Arbitrary Sampling},
	Volume = {abs/1411.5873},
	Year = {2014}}

@inproceedings{CQ-adaptive-sampling,
	Author = {Dominik Csiba and Zheng Qu and Peter Richt{\'{a}}rik},
	Booktitle = {Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015},
	Pages = {674--683},
	Title = {Stochastic Dual Coordinate Ascent with Adaptive Probabilities},
	Year = {2015}}

@inproceedings{zz-sdca-sampling,
	Author = {Peilin Zhao and Tong Zhang},
	Booktitle = {{Proceedings of the 32nd International Conference on Machine Learning}},
	Pages = {1--9},
	Title = {{Stochastic Optimization with Importance Sampling for Regularized Loss Minimization}},
	Volume = 37,
	Year = 2015}

@inproceedings{HLM2015,
	Author = {Hofmann, Thomas and Lucchi, Aurelien and Lacoste-Julien, Simon and McWilliams, Brian},
	Booktitle = {NIPS 2015},
	Pages = {2296--2304},
	Title = {Variance Reduced Stochastic Gradient Descent with Neighbors},
	Year = {2015}}

@article{AY2015-coord,
	Author = {{Allen-Zhu}, Zeyuan and Qu, Zheng and Richt{\'{a}}rik, Peter and Yuan, Yang},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Journal = {ArXiv e-prints},
	Month = dec,
	Title = {Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling},
	Volume = {abs/1512.09103},
	Year = {2015}}

@misc{e2lsh,
	Author = {Alexandr Andoni},
	Howpublished = {\url{http://www.mit.edu/~andoni/LSH/}},
	Title = {{E2LSH}},
	Year = {2004}}

@phdthesis{Andoni2009thesis,
	Author = {Andoni, Alexandr},
	School = {MIT},
	Title = {Nearest Neighbor Search: the Old, the New, and the Impossible},
	Year = 2009}

@article{NNpq2011,
	Author = {Herv{\'{e}} J{\'{e}}gou and Matthijs Douze and Cordelia Schmid},
	Journal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	Number = {1},
	Pages = {117--128},
	Title = {Product Quantization for Nearest Neighbor Search},
	Volume = {33},
	Year = {2011}}

@article{NNopq2014,
	Author = {Tiezheng Ge and Kaiming He and Qifa Ke and Jian Sun},
	Journal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	Number = {4},
	Pages = {744--755},
	Title = {Optimized Product Quantization},
	Volume = {36},
	Year = {2014}}

@article{Kaczmarz1937,
	Author = {Kaczmarz, Stefan},
	Journal = {Bulletin International de l'Academie Polonaise des Sciences et des Lettres},
	Pages = {355--357},
	Title = {Angen{\"a}herte aufl{\"o}sung von systemen linearer gleichungen},
	Volume = {35},
	Year = {1937}}

@article{StrohmerVershynin2009,
	Author = {Strohmer, Thomas and Vershynin, Roman},
	Journal = {Journal of Fourier Analysis and Applications},
	Number = {2},
	Pages = {262--278},
	Publisher = {Springer},
	Title = {A randomized Kaczmarz algorithm with exponential convergence},
	Volume = {15},
	Year = {2009}}

@article{JHSPS-VR-Framework-parallel,
	Author = {Sashank J. Reddi and Ahmed Hefny and Suvrit Sra and Barnab{\'{a}}s P{\'{o}}czos and Alexander J. Smola},
	Journal = {NIPS},
	Title = {On Variance Reduction in Stochastic Gradient Descent and its Asynchronous Variants},
	Year = {2015}}

@article{KonecnyRichtarik2013,
	Author = {{Kone{\v c}n{\'y}}, J. and {Richt{\'a}rik}, P.},
	Journal = {ArXiv e-prints},
	Month = dec,
	Title = {{Semi-Stochastic Gradient Descent Methods}},
	Volume = {abs/1312.1666},
	Year = 2013}

@article{HazanBook,
	Author = {Elad Hazan},
	Journal = {Foundations and Trends in Machine Learning},
	Number = {XX},
	Pages = {1--168},
	Title = {{DRAFT}: Introduction to Online Convex Optimimization},
	Volume = {XX},
	Year = {2015}}

@article{GarberHazan2015-PCA,
	Author = {{Garber}, Dan and {Hazan}, Elad},
	Journal = {ArXiv e-prints},
	Month = sep,
	Title = {Fast and Simple {PCA} via Convex Optimization},
	Volumn = {abs/1509.05647},
	Year = 2015}

@inproceedings{Shamir2015,
	Archiveprefix = {arXiv},
	Arxivid = {1409.2848},
	Author = {Shamir, Ohad},
	Booktitle = {Proceedings of The 32nd International Conference on Machine Learning},
	Eprint = {1409.2848},
	File = {:D$\backslash$:/Mendeley Desktop/Shamir - 2014 - A Stochastic PCA Algorithm with an Exponential Convergence Rate.pdf:pdf},
	Mendeley-Groups = {Optimization/Variance Reduction,Optimization,Optimization/[with Yuan Yang]},
	Pages = {144----153},
	Series = {ICML 2015},
	Title = {{A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate}},
	Url = {http://arxiv.org/pdf/1409.2848.pdf http://arxiv.org/abs/1409.2848v1},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/pdf/1409.2848.pdf%20http://arxiv.org/abs/1409.2848v1}}

@incollection{StopwastingGradient,
	Author = {Harikandeh, Reza and Ahmed, Mohamed Osama and Virani, Alim and Schmidt, Mark and Kone\v{c}n\'{y}, Jakub and Sallinen, Scott},
	Booktitle = {Advances in Neural Information Processing Systems 28},
	Editor = {C. Cortes and N.D. Lawrence and D.D. Lee and M. Sugiyama and R. Garnett},
	Pages = {2242--2250},
	Publisher = {Curran Associates, Inc.},
	Title = {StopWasting My Gradients: Practical SVRG},
	Url = {http://papers.nips.cc/paper/5711-stopwasting-my-gradients-practical-svrg.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5711-stopwasting-my-gradients-practical-svrg.pdf}}

@article{ms2gd,
	Author = {Jakub Konecn{\'{y}} and Jie Liu and Peter Richt{\'{a}}rik and Martin Tak{\'{a}}c},
	Journal = {CoRR},
	Title = {mS2GD: Mini-Batch Semi-Stochastic Gradient Descent in the Proximal Setting},
	Url = {http://arxiv.org/abs/1410.4744},
	Volume = {abs/1410.4744},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1410.4744}}

@article{DuchiHazanSinger2011,
	Author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	Journal = {The Journal of Machine Learning Research},
	Pages = {2121--2159},
	Publisher = {JMLR. org},
	Title = {Adaptive subgradient methods for online learning and stochastic optimization},
	Volume = {12},
	Year = {2011}}

@article{UniVR,
	Author = {Zeyuan Allen-Zhu and Yang Yuan},
	Journal = {CoRR},
	Title = {UniVR: {A} Universal Variance Reduction Framework for Proximal Stochastic Gradient Method},
	Volume = {abs/1506.01972},
	Year = {2015}}

@article{exploitingstructure,
	Author = {Zeyuan Allen-Zhu and Yang Yuan and Karthik Sridharan},
	Journal = {CoRR},
	Title = {Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters},
	Volume = {abs/1602.02151},
	Year = {2016}}

@inproceedings{escapesaddle,
	Author = {Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
	Booktitle = {COLT},
	Title = {Escaping From Saddle Points - Online Stochastic Gradient for Tensor Decomposition.},
	Year = 2015}

@article{GDconvergetominimizer,
	Author = {Jason D. Lee and Max Simchowitz and Michael I. Jordan and Benjamin Recht},
	Journal = {CoRR},
	Title = {Gradient Descent Converges to Minimizers},
	Volume = {abs/1602.04915},
	Year = {2016}}

@article{mimiciii,
	Author = {Saeed, Mohammed and Villarroel, Mauricio and Reisner, Andrew T and Clifford, Gari and Lehman, Li-Wei and Moody, George and Heldt, Thomas and Kyaw, Tin H and Moody, Benjamin and Mark, Roger G},
	Journal = {Critical care medicine},
	Number = {5},
	Pages = {952},
	Publisher = {NIH Public Access},
	Title = {Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC-II): a public-access intensive care unit database},
	Volume = {39},
	Year = {2011}}
